---
title: "Using Coereba"
package: Coereba
author:
- name: David Rach
  email: drach@som.umaryland.edu
  affiliation: University of Maryland, Baltimore
date: "`r BiocStyle::doc_date()`"
format:
  html:
    minimal: true
    theme: flatly
vignette: |
  %\VignetteIndexEntry{Workflow}
  %\VignetteKeywords{Workflow}
  %\VignettePackage{Coereba}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{quarto::html}
  %\VignetteDepends{BiocStyle}
---

```{r}
#| eval: FALSE
knitr::opts_chunk$set(
  eval = FALSE,
  collapse = TRUE,
  comment = "#>"
)
```

```{r}
#| label: BackgroundLibraryLoadForVignette
#| echo: FALSE
#| warning: FALSE
#| results: "hide"

suppressPackageStartupMessages({
library(Coereba)
library(BiocStyle)
library(flowCore)
library(flowWorkspace)
library(CytoML)
library(openCyto)
#library(ggcyto)  
library(data.table)
library(dplyr)
library(purrr) 
library(stringr)
library(ggplot2)
library(gt)
#library(plotly)
#library(htmltools)
})
```

# Setup

## Installing Coereba

We are in the process of preparing Coereba to submit to Bioconductor later this year. Until then, the developmental version can be installed via GitHub.

```{r}
#| label: "Installing Coereba"
#| eval: FALSE

if(!require("remotes")){install.packages("remotes")}
remotes::install_github("https://github.com/DavidRach/Coereba")

# install.packages("BiocManager")
# BiocManager::install("Coereba")
```

## Load Required Libraries

Coereba primarily relies on the infrastructure provided `r Biocpkg("flowWorkspace")` and other Bioconductor cytometry R packages. It additionally leverages various `r CRANpkg("tidyverse")` packages available via CRAN. Before starting, it is important to make sure all required packages are first installed, and that library is called for each to make them available. 

```{r}
#| label: "Load Libraries"

# CRAN packages: install.packages("ThePackageName")

 library(dplyr)
 library(purrr) 
 library(stringr)
 library(ggplot2)
# library(gt)
# library(plotly)
# library(htmltools)
# library(data.table)

# Bioconductor packages: BiocManager::install("ThePackageName")

library(Coereba)
library(flowCore)
library(flowWorkspace)
library(openCyto)
library(ggcyto)  

# GitHub packages: remotes::install_github("DavidRach/Luciernaga")
library(Luciernaga)
```

## Locate your files

You will next need to provide to your computer the location where your .fcs files of interest are stored. An example of how the author does this for the various computer operating systems is shown below. Please modify the file.paths accordingly to match your own username and folder location.

```{r}
#| label: "File Paths"
#| eval: FALSE

# For Windows Operating Systems

File_Location <- file.path("C:", "Users", "JohnDoe", "Desktop", "TodaysExperiment")
FCS_Pattern <- ".fcs$"
FCS_Files <- list.files(path = File_Location, pattern = FCS_Pattern,
                        full.names = TRUE, recursive = FALSE)

# For Mac

# For Linux
# File_Location <- file.path("/home", "JohnDoe", "Desktop", "TodaysExperiment")
```

For this vignette, we will be utilizing several .fcs files that are stored within Coereba's extdata folder. These consist of unmixed .fcs files from a 32 fluorophore Spectral Flow Cytometry panel. We manually gated down to CD4-CD8- (DN) T cells, from which we downsampled up to 1000 cells to create a sufficiently small dataset to use for the R package documentation. 

```{r}
#| label: "Accessing Coereba's FCS files"
File_Location <- system.file("extdata", package = "Coereba")
FCS_Pattern <- ".fcs$"
FCS_Files <- list.files(path = File_Location, pattern = FCS_Pattern,
                        full.names = TRUE, recursive = FALSE)
head(FCS_Files, 3)
```

 

## Creating a GatingSet

### flowWorkspace and openCyto

Working with the unmixed .fcs files we have identified above, we will group them into a GatingSet object where we can further interact with them.

```{r}
#| label: GatingSet
UnmixedFCSFiles <- FCS_Files
UnmixedCytoSet <- load_cytoset_from_fcs(UnmixedFCSFiles, truncate_max_range = FALSE,
                                        transformation = FALSE)
UnmixedGatingSet <- GatingSet(UnmixedCytoSet)
UnmixedGatingSet
```

Now that we have created a GatingSet object, we will generate list of the fluorophores and markers present. We will then exclude from this list markers that don't require transformation (FSC, SSC, etc.) For this example, we will biexponentially transform our data using the `r Biocpkg("flowWorkspace")` `flowWorkspace::flowjo_biexp_trans()`.

```{r}
#| label: "Biexponential Transformation"
#| message: false
Markers <- colnames(UnmixedCytoSet)
KeptMarkers <- Markers[-grep("Time|FS|SC|SS|Original|-W$|-H$|AF", Markers)]

MyBiexponentialTransform <- flowjo_biexp_trans(channelRange = 256, maxValue = 1000000,
                                               pos = 4.5, neg = 0, widthBasis = -1000)
TransformList <- transformerList(KeptMarkers, MyBiexponentialTransform)
UnmixedGatingSet <- transform(UnmixedGatingSet, TransformList)
```

For this example, we will apply a `r Biocpkg("openCyto")`gating template that can be found in the extdata folder to apply a gate to distinguish Vdelta2 cells from other DN T cells. 

```{r}
#| label: "openCyto Gating"
UnmixedGates <- fread(file.path(path = File_Location, pattern = 'GatesUnmixed.csv'))
UnmixedGating <- gatingTemplate(UnmixedGates)
gt_gating(UnmixedGating, UnmixedGatingSet)
```

```{r}
plot(UnmixedGatingSet)
```

We can additionally verify that the gating of the cell populations of interest was correct, by visualizing the gates using `r Biocpkg("ggcyto")` or the `Luciernaga::Utility_GatingPlots` function from the `Luciernaga` package. 

```{r}
MyPlot <- Utility_GatingPlots(x=UnmixedGatingSet[4], sample.name=c("GROUPNAME", "TUBENAME"),
                              removestrings=".fcs", subset="root", gtFile=UnmixedGates,
                              DesiredGates=NULL, returnType="plots", outpath = getwd(),
                              therows=1, thecolumns=2)

MyPlot
```

### CytoML

An alternative approach to creating a new GatingSet with `r Biocpkg("openCyto")`, would to be to import an existing FlowJo workspace using `r Biocpkg("CytoML")`. The workflow for this approach would look something as follows:

```{r}
#| label: "CytoML example"
#| eval: FALSE

# For Windows Operating Systems
folder <- file.path("C:", "Users", "JohnDoe", "Desktop", "TodaysExperiment")
wsp <- list.files(pattern=".wsp", full.names=TRUE)
```

```{r}
#| label: BackgroupWspLoadForVignette
#| echo: FALSE
#| warning: FALSE
#| results: "hide"
folder <- system.file("extdata", package = "Coereba")
wsp <- list.files(folder, pattern=".wsp", full.names=TRUE)
```

```{r}
#| label: CytoML workflow
library(CytoML)
ws <- open_flowjo_xml(wsp[1])
CytoML_GS <- flowjo_to_gatingset(ws, name=1, path = folder, additional.keys="GROUPNAME")
CytoML_GS
```

```{r}
#| label: Checking CytoML output
library(Luciernaga)

MyPlot <- Utility_GatingPlots(x=CytoML_GS[27], sample.name=c("GROUPNAME", "TUBENAME"),
                              removestrings=".fcs", subset="root", gtFile=UnmixedGates,
                              DesiredGates=NULL, returnType="plots", outpath = getwd(),
                              therows=1, thecolumns=2)

MyPlot
```

# Coereba

Having set up a GatingSet and applied the transformations and gates, we can now proceed to the main `Coereba` workflow. 

For this example, we will focus on just 4 of the 32 markers, CD16 (BV570), CXCR5 (RB780), HLA-DR(PE-Vio770), and Vdelta2 (BUV661). Most cord DN T cells are negative for these markers, but 5-25% are positive, so they are good examples to showcase the gate adjustment mechanisms. The process when working with all 32-markers is similar, but will take a little more compute time. 

```{r}
#| label: Designating markers

# BV570=CD16, RB780=CXCR5, BUV661=Vd2, PE-Vio770=HLA-DR

MarkersForToday <- c("Comp-BV570-A", "Comp-RB780-A", "Comp-BUV661-A", "Comp-PE-Vio770-A")
```


## Return a Coereba Gate cutoff template

The first step is to create a .csv file, containing the individual specimens, and the individual markers of interest. Each cell within the .csv file will correspond to the MFI for a given marker for a given individual where positive expression of a marker transitions to becoming a negative (referred here to as a splitpoint). 

These could be specified out individually, or derrived in an automated fashion. In Coereba, we leverage the `r Biocpkg("openCyto")` automated gating functions (primarily the gate_mindensity option) to save us from the eye-strain of typing everything out. We will run the `Coereba_GateCutoffs()` function on each specimen in the GatingSet, and use the `r CRANpkg("dplyr")` packages `bind_rows()`to gather the rows into a data.frame object. We in turn can save this as a .csv for later use (or minor hand editing). 

```{r}
# Designate a location file.path to save the calculated splitpoints .csv to. 
StorageLocationForSplitpoints <- file.path("C:", "Users", "JohnDoe", "Desktop")

# We will use a temp() folder for this documentation example. 
StorageLocationForSplitpoints <- tempdir()

TheGateCutoffs <- purrr::map(.x=UnmixedGatingSet, .f=Coereba_GateCutoffs,
  subset="root", sample.name=c("GROUPNAME"), desiredCols=MarkersForToday) |> bind_rows()

TheFileName <- file.path(StorageLocationForSplitpoints, "InitialGates.csv")

write.csv(TheGateCutoffs, TheFileName, row.names=FALSE)
```

```{r}
TheGateCutoffs
```

With these intial split points calculated, we can visualize how well the splitpoints were calculated by plotting them as red-lines using the `Luciernaga` packages `Utility_NbyNPlots()` (visualizing all marker combinations for an individual specimen) and `Utility_UnityPlots()` (visualizing a marker combination across all specimens) functions. The resulting plots can be returned to R using either the returntype= "plots" or "patchwork" arguments, or saved to the directory by providing the "pdf" argument instead. 

```{r}
#| label: NbyN plot check
#| message: FALSE
#| warning: FALSE

# Designate a location
StorageLocationForPlotPDF <- file.path("C:", "Users", "JohnDoe", "Desktop")

# We will use a temp() folder for this documentation example. 
StorageLocationForPlotPDF <- tempdir()

Plot <- Utility_NbyNPlots(x=UnmixedGatingSet[4], sample.name=c("GROUPNAME"), experiment="ABs",
condition="DNs", removestrings=".fcs", marginsubset="root", gatesubset="root", 
ycolumn="Comp-PE-Vio770-A", bins=150, clearance=0.1, 
gatelines=TRUE, reference=TheGateCutoffs, outpath=StorageLocationForPlotPDF, returntype="patchwork")
```

When a marker has distinct positive or negative markers, the initial estimated location works well. 

```{r}
Plot
```

However, when everything is uniformly positive or negative, or more subtle shift, these estimated locations can be quite off, and the respective splitpoints will need to be corrected. If a particular marker(s) is consistently off, we can redo the splitpoints for individual markers by providing gate_range arguments to constrain the mindensity to searching within a particular area. 

The simplest way to do this is to set the `Coereba_GateCutoffs()` returnTemplate argument to TRUE, which will return a TemplateForGates.csv based off the openCyto template .csv.

```{r}
#| label: Return an openCyto template

# Designate a location file.path to save the template to. 
StorageLocationForTemplate <- file.path("C:", "Users", "JohnDoe", "Desktop")

# We will use a temp() folder for this documentation example. 
StorageLocationForTemplate <- tempdir()

ReturnATemplate <- Coereba_GateCutoffs(x=UnmixedGatingSet[1],
  subset="root", sample.name="GROUPNAME", desiredCols=MarkersForToday, 
  returnTemplate=TRUE, outpath=StorageLocationForTemplate)   
```

```{r}
TheTemplate <- list.files(StorageLocationForTemplate,
 pattern="TemplateForGates.csv", full.names=TRUE)

TheTemplateCSV <- read.csv(TheTemplate, check.names=FALSE)
```

```{r}
#| echo: FALSE
TheTemplateCSV
```

We can then manually update with the gate_range arguments. 

```{r}
#On your own workstation

UpdatedTemplatePath <- file.path("C:", "Users", "JohnDoe", "Desktop",
"UpdatedTemplateForGates.csv")

# For our documentation's example

folder <- system.file("extdata", package = "Coereba")

UpdatedTemplatePath <- list.files(folder, pattern="UpdatedTemplateForGates.csv", full.names=TRUE)

UpdatedTemplate <- read.csv(UpdatedTemplatePath, check.names=FALSE)
```

```{r}
UpdatedTemplate
```

With this done, we can provide it back to `Coereba_GateCutoffs()` with the GateOverwrite argument set to TRUE. This will restart the calculation of the splitpoints.

```{r}
TheUpdatedGateCutoffs <- purrr::map(.x=UnmixedGatingSet, .f=Coereba_GateCutoffs,
  subset="root", sample.name="GROUPNAME", desiredCols=MarkersForToday,
  GatingTemplate=UpdatedTemplatePath, GateOverwrite=TRUE) %>% bind_rows()

# Designate a location file.path to save the template to. 
StorageLocationForUpdatedSplitpoints <- file.path("C:", "Users", "JohnDoe", "Desktop")

# We will use a temp() folder for this documentation example. 
StorageLocationForUpdatedSplitpoints <- tempdir()

SecondGates <- file.path(StorageLocationForUpdatedSplitpoints, "SecondGates.csv")
write.csv(TheUpdatedGateCutoffs, SecondGates, row.names=FALSE)
```

```{r}
TheUpdatedGateCutoffs
```

This ultimately allows the splitpoint gate estimates to be closer to the true positive/negative split, resulting in less total adjustments that need to be done via the Coereba Shiny app.

```{r}
#| label: NbyN plot check 2
#| message: FALSE
#| warning: FALSE

StorageLocationForPlotPDF <- tempdir()

UpdatedPlot <- Utility_NbyNPlots(x=UnmixedGatingSet[4], sample.name=c("GROUPNAME"), experiment="ABs",
condition="DNs", removestrings=".fcs", marginsubset="root", gatesubset="root", 
ycolumn="Comp-PE-Vio770-A", bins=150, clearance=0.1, 
gatelines=TRUE, reference=TheUpdatedGateCutoffs, outpath=StorageLocationForPlotPDF, returntype="patchwork")
```

```{r}
UpdatedPlot
```

## Coereba_App

With the estimated splitpoints having been calculated, we still need to make sure to correct the location for the odd specimen that is of. We have created a R Shiny App to facilitate this process. When provided with the .csv of splitpoints, it will load in the GatingSet object, and plot an interactive version of `Utility_UnityPlot()` from the `Luciernaga` package, visualizing the splitpoint for a given marker across all individuals as red vertical lines. These can then be updated via the graphical user interface (GUI) by clicking just above the axis. 

First off, remember the location you saved the splitpoints .csv, as the Shiny App will ask you to find it later:

```{r}
#| label: Remembering Storage Location

# Wherever you stored it
File_Location <- file.path("C:", "Users", "JohnDoe", "Desktop")

# For our example documentation
File_Location <- system.file("extdata", package = "Coereba")
TheCSV <- file.path(File_Location, "SecondGates.csv")
TheCSVData <- read.csv(TheCSV, check.names=FALSE)
head(TheCSVData)
```

Similarly, make sure to remember what you called your GatingSet ("UnmixedGatingSet" for our example), and the sample.name keyword used to identify individual specimens, as you will need to also provide these values to the app.

We will now launch the Shiny App by calling the `Coereba_App()` function

```{r}
#| label: Coereba_App
#| eval: false

#library(DT)
#library(plotly)
#library(shiny)
#library(shinydashboard)

Coereba_App()
```

Upon launch, you land inside the Upload CSV File tab (located on the upper left). Go ahead and click on the Import .csv button.   

![](`r system.file("extdata", "ShinyLanding.png", package = "Coereba")`){width="75%"}

Proceed to find and upload your SecondGates.csv equivalent (containing the updated splitpoints based on the gate_range constraints) by navigating to the storage folder location and select it. Once done, the contents will appear in the space on the right.

![](`r system.file("extdata", "ShinySplitpointsLoaded.png", package = "Coereba")`){width="75%"}

Next, you will select the "Upload a Gating Set" tab on the upper left.

What we now see is a way to provide arguments to the interactive version of `Utility_UnityPlots()`

Enter the information about your GatingSet ("UnmixedGatingSet" for this example), select your desired x and y parameters ("Comp-BUV661-A", etc), and the Sample.Name keyword that designates the respective specimens. The bins argument will adjust how th cells are visualized, with higher numbers being finer detail. Clearance is a proportion used to create additional space around the edge of the plot, which is set based on the values for the respective subset provided by the margin argument. The cells being plotted come from the "gate" subset box.  Finally, click Display Estimated Gate Cutoffs to visualize the splitpoints as vertical red lines.  

![](`r system.file("extdata", "ShinyDetailsLoaded.png", package = "Coereba")`){width="75%"}

Once this is done, click Generate Plots. If you view the console of the main R session, you will see the Utility_NbyNplot messages running as the plots are generated. How long it will take to load in the plots depends on the number of specimens, and the size of the files. Once the plots are loaded, wait a couple of seconds until you can hover with your mouse over the plots before clicking to avoid having the App freeze up. 

![](`r system.file("extdata", "ShinyVisuals.png", package = "Coereba")`){width="75%"}

For standard workflow, scroll examining how the splitpoints were assigned for the individual samples. When you encounter a splitpoint line that was incorrectly set, hover just above the just above the x-axis for the correct location, and click on the spot with your mouse (see blue arrow for an example). 

![](`r system.file("extdata", "ShinyUpdating.png", package = "Coereba")`){width="75%"}

When you click just above the axis for the corrected splitpoint, you should see a click event captured message pop up in the console window of the Main R environment. If you click to far above the axis, you will not see this message displayed. Similarly, this message can be used to remember at what sample you left off when scrolling. All these clicks will save the coordinate as a splitpoint for that given marker and individual to a data.frame we will see on the next tab. 

In terms of accidentally clicking the wrong location, only the last click for a respective sample will be used, so in case of a misclick, reclick on the correct location. 

![](`r system.file("extdata", "ConsoleClicks.png", package = "Coereba")`){width="75%"}

Once you have corrected everything for a particular marker, switch down to the next x-axis marker, and regenerate the plots. Once they are loaded, proceed to correct the splitpoints for each additional marker.

![](`r system.file("extdata", "CorrectSplitpoints.png", package = "Coereba")`){width="75%"}

Once this is complete, navigate to the Click Data tab on the upper left. You will see the click events in their totality. You will next need to export this data. 

![](`r system.file("extdata", "ClickDataExport.png", package = "Coereba")`){width="75%"}

Due to computer safety reasons, Shiny Apps are not allowed to write directly to your computer file system. So you will need to manually type in the file name and the file.path to a storage location. Once this is done, click "Export Click Data". If this was done successfully, you should see the following notice appear. 

![](`r system.file("extdata", "CheckoutNotice.png", package = "Coereba")`){width="75%"}

Finally, close out of the Shiny window, and hit the red stop button on the right-hand of the console to return back to Positron. 

When working with a large dataset, we have observed the ShinyApp start to slow after a couple markers. When this occurs, save the click file to your destination folder, close the ShinyApp, and relaunch. Correct a couple additional markers, and save the Export Click Data again with a different name. After everything is gated, the same function used to update the Splitpoint.csv can be used to grab all .csv files from within a folder in a single go. 
 
(Note for developers: Shiny relies heavily on reactive R, which is not the maintainer's coding forte, so some additional work to speed things up behind the scenes is likely required. If this is your area of expertise, feel free to contribute!)


# Updating the Splitpoints

Having gone through and corrected the splitpoints with `Coereba_App()`, it is time to convert your validated click-data and update the SecondGates.csv to reflect the changes. To facilitate this, we will use the `Coereba_UpdateGates()` function. This can be used to update for either a single click-data .csv, or the file.path to the folder containing all the click-data .csv files in one go.

In our case, we will update using the saved click-data from above stored inside the extdata folder. 
```{r}
# Wherever you stored it
File_Location <- file.path("C:", "Users", "JohnDoe", "Desktop")

# For our example documentation
File_Location <- system.file("extdata", package = "Coereba")
TheOldCSV <- file.path(File_Location, "SecondGates.csv")
TheClickInfo <- file.path(File_Location, "CorrectSplitpointLocations.csv")
TheClickData <- read.csv(TheClickInfo, check.names=FALSE)
TheClickData
```

By comparison, the data from SecondGates that will be updated
```{r}
TheOldData <- read.csv(TheOldCSV, check.names=FALSE)
TheOldData
```

We can then run `Coereba_UpdateGates()` and examine how the PE-Vio770 values are correspondingly updated.

```{r}
ShinyGatesSplitpoints <- Coereba_UpdateGates(Clicks=TheClickInfo, Old=TheOldCSV,
  export=FALSE, outpath=NULL, fileName="UpdatedCSV")

ShinyGatesSplitpoints
```

```{r}
# Designate a location file.path to save the Shiny Updated Splitpoints to
StorageLocationForShinyUpdatedSplitpoints <- file.path("C:", "Users", "JohnDoe", "Desktop")

# We will use a temp() folder for this documentation example. 
StorageLocationForShinyUpdatedSplitpoints <- tempdir()

ShinyGatesPath <- file.path(StorageLocationForShinyUpdatedSplitpoints, "ShinyGates.csv")
write.csv(ShinyGatesSplitpoints, ShinyGatesPath, row.names=FALSE)
```

We in turn can validate this further by  by re-running `Luciernaga` `Utility_NbyNPlots()` or `Utility_UnityPlots()` using the updated GateCutoff.csv and see how things look now following our intervention. 

```{r}
#| label: NbyN plot check 3
#| message: FALSE
#| warning: FALSE

StorageLocationForPlotPDF <- tempdir()

UpdatedPlotAfterShiny <- Utility_NbyNPlots(x=UnmixedGatingSet[4], sample.name=c("GROUPNAME"), experiment="ABs",
condition="DNs", removestrings=".fcs", marginsubset="root", gatesubset="root", 
ycolumn="Comp-PE-Vio770-A", bins=150, clearance=0.1, 
gatelines=TRUE, reference=ShinyGatesSplitpoints, outpath=StorageLocationForPlotPDF, returntype="patchwork")
```

```{r}
UpdatedPlotAfterShiny
```

# Coereba

With the gate locations now finalized, it's time to run Coereba and classify each individual cell within  a specimen by it's marker expression relative to their respective splitpoint location. Cells that share marker expressions ultimately end up in the same clusters. We will use the `Utility_Coereba()` function for this process, providing both the validated ShinyGates and our GatingSet.  

```{r}
#| label: Utility_Coereba

# Wherever you stored it
File_Location <- file.path("C:", "Users", "JohnDoe", "Desktop")

# For our example documentation
File_Location <- system.file("extdata", package = "Coereba")

CheckedGates <- file.path(File_Location, "ShinyGates.csv")

CoerebaData <- Utility_Coereba(gs=UnmixedGatingSet, subsets="root",
 sample.name="GROUPNAME", reference=CheckedGates, starter="Comp-PE-Vio770-A",
 inverse.transform = TRUE, returnType="data", Individual=FALSE, outpath=NULL,
 columns = MarkersForToday)
```

```{r}
head(CoerebaData)
```

In the above case, we set returnType = "data", and Individual = "FALSE", resulting in a single data.frame containing the content for all specimens.  Please refer to the documentation for `Utility_Coereba()` for additional options. 


# Save to FCS file (optional)

Once `Utility_Coereba()` has been run, we can send the output to an .fcs file. In this process, any metadata present will be converted over to numeric keyword format, with the actual information stored away as keywords for later retrieval. Exporting as an .fcs can can be useful when we are planning to export to an .fcs file for downstream unsupervised analysis, as it allows us to run dimensionality visualization algorithms, gate the islands, and then retrieve Coereba data as far as gating and metadata from cells within those respective islands. 

```{r}
#| label: Coereva_FCSExport

# Designate a location file.path to save the Shiny Updated Splitpoints to
StorageLocationForFCS <- file.path("C:", "Users", "JohnDoe", "Desktop")

# We will use a temp() folder for this documentation example. 
StorageLocationForFCS <- tempdir()

FCSFile <- Coereba::Coereba_FCSExport(data=CoerebaData, gs=UnmixedGatingSet[1],
      returnType="fcs", outpath=StorageLocationForFCS, filename="CoerebaTest",
      nameAppend="", Aggregate=FALSE)
```

Likewise, once we are done with the unsupervised analysis, we can retrieve the same data back to R through the `Coereba_FCS_Reversal()` function. 

```{r}
#| label: Coereba_FCS_Reversal
FCSPath <- file.path(StorageLocationForFCS, "CoerebaTest.fcs")
RetrievedData <- Coereba::Coereba_FCS_Reversal(Coereba=FCSPath)
# View(RetrievedData)
```

```{r}
head(RetrievedData, 5)
```

## Normalization Bypass

Alternatively, if you are planning to normalize the files with CytoNorm, you don't want to return a concatenated file, but individual cytoframe objects. Here is an example workflow:

```{r}
#| label: ListOfFlowFrames
CoerebaFlowFrame <- Utility_Coereba(gs=UnmixedGatingSet, subsets="root",
 sample.name="GROUPNAME", reference=CheckedGates, starter="Comp-PE-Vio770-A",
 inverse.transform = TRUE, returnType="flowframe", Individual=TRUE, outpath=NULL,
 columns = MarkersForToday)
```

```{r}
CoerebaFlowFrame1 <- unlist(CoerebaFlowFrame)

FlowSet <- flowCore::flowSet(CoerebaFlowFrame1)
FlowGS <- GatingSet(FlowSet)

MarkersUpdated <- gsub("Comp-", "", MarkersForToday)
```

```{r}
MyBiexponentialTransform <- flowjo_biexp_trans(channelRange = 256, maxValue = 1000000,
                                               pos = 4.5, neg = 0, widthBasis = -1000)
TransformList <- transformerList(MarkersUpdated, MyBiexponentialTransform)

InverseBiexponential <- flowjo_biexp(inverse=TRUE, channelRange=256, maxValue=1000000, pos=5.25, neg=0, width=-1000)
ReverseBiexponential <- transformList(MarkersUpdated, InverseBiexponential)

FlowSet_Transformed <- transform(FlowGS, TransformList)
```

```{r}
ShinyGatesSplitpoints2 <- ShinyGatesSplitpoints
colnames(ShinyGatesSplitpoints2) <- gsub("Comp-", "", colnames(ShinyGatesSplitpoints2))

PostCoereba <- Utility_NbyNPlots(x=FlowGS[4], sample.name=c("GROUPNAME"), experiment="ABs",
condition="DNs", removestrings=".fcs", marginsubset="root", gatesubset="root", 
ycolumn="PE-Vio770-A", bins=150, clearance=0.1, 
gatelines=TRUE, reference=ShinyGatesSplitpoints2, outpath=StorageLocationForPlotPDF, returntype="patchwork")
```

```{r}
PostCoereba
```

### Readding filtering data

```{r}
Specimen <- function(x){
  pattern <- "([A-Z]+[0-9]+_[0-9]+)(?=_SEB)"
  result <- stringr::str_extract(x, pattern)
  result <- data.frame(Specimen = result)
  return(result)
}

Experiment <- function(x){
  pattern <- "(?<=_)AB_[0-9]{2}(?=_)" 
  result <- stringr::str_extract(x, pattern)
  result <- data.frame(Experiment = result)
  return(result)
}
```

```{r}
OriginalPD <- pData(UnmixedGatingSet)
ValuesOriginal <- OriginalPD |> pull(name)
TheSpecimen <- map(ValuesOriginal, .f=Specimen) %>% bind_rows()
TheExperiment <- map(ValuesOriginal, .f=Experiment) %>% bind_rows()
```

```{r}
OtherPD <- pData(FlowGS)
UpdatedPD <- cbind(OtherPD, TheSpecimen, TheExperiment)
UpdatedPD <- UpdatedPD |> mutate(Donor = str_replace(Specimen, "_[0-9]+$", ""))
pData(FlowGS) <- UpdatedPD
```

### Subsetting Controls

```{r}
TheNormies <- subset(FlowGS, Donor=="NY068")
#pData(TheNormies)
NormCounts <- gs_pop_get_stats(TheNormies, nodes="root", type="count")
TheCount <- sum(NormCounts$count)
NormiesCS <- gs_cyto_data(TheNormies)
#pData(NormiesCS)
TheNewNormies <- cytoset_to_flowSet(NormiesCS)
```

```{r}
Batch <- pData(TheNewNormies)$Experiment
```

```{r}
library(CytoNorm)

NormPath <- file.path("C:", "Users", "12692", "Desktop", "CytoNorm")

model <- CytoNorm.train(files=TheNewNormies,
                        labels=Batch,
                        channels=MarkersUpdated,
                        transformList=NULL,
                        seed=1989,
                        plot=TRUE,
                        verbose=TRUE,
                        normMethod.train = "QuantileNorm.train",
                        normParams = list(nQ = 99),
                        FlowSOM.params = list(nCells = TheCount,
                          xdim = 15, ydim = 15, nClus = 9,
                          scale = FALSE, colsToUse = MarkersUpdated),
                        outputDir = NormPath,
                        clean = TRUE,
                        recompute = TRUE)
```

```{r}
LongTermStorage <- file.path(NormPath, "SmallModel.rds")
saveRDS(object = model, file = LongTermStorage)
```

```{r}
LongTermStorage <- file.path(NormPath, "SmallModel.rds")
previousModel <- readRDS(LongTermStorage)
goal_q <- getCytoNormQuantiles(previousModel)
Batch <- pData(TheNormies)$Experiment
#ForClustering1 <- GetChannels(object = NormalizeGS2[[1]], markers = ForClustering)

model_Distribution <- CytoNorm.train(files=TheNewNormies,
                        labels=Batch,
                        channels=MarkersUpdated,
                        transformList=NULL,
                        seed=1989,
                        plot=TRUE,
                        verbose=TRUE,
                        normParams = list("goal" = goal_q),
                        FlowSOM.params = list(nCells = TheCount,
                          xdim = 15, ydim = 15, nClus = 9,
                          scale = FALSE, colsToUse=MarkersUpdated),
                        outputDir = NormPath,
                        clean = TRUE,
                        recompute = TRUE)
```


And finally, we normalize everyone else
```{r}
AllNormies <- FlowGS
AllCS <- gs_cyto_data(AllNormies)
AllFS <- cytoset_to_flowSet(AllCS)

Batch <- pData(AllFS)$Experiment

# Use model or model_Distribution

NormalizeAttempt <- CytoNorm.normalize(model=model, 
                                       files=AllFS,
                                       labels=Batch,
                                       transformList = NULL,
                                       verbose=TRUE,
                                       prefix="Norm_",
                                       transformList.reverse = NULL,
                                       outputDir= NormPath,
                                       clean = TRUE, 
                                       write = FALSE)
```

And finally, we update the metadata for the new GatingSet
```{r}
pd3 <- pData(NormalizeAttempt)
colnames(pd3) <- "thename"

pd <- pData(FlowGS)
UpdatedPD <- cbind(pd3, pd)

pData(NormalizeAttempt) <- UpdatedPD
```

```{r}
#| eval: FALSE
Population <- "TestSet"
UpdatedGS <- GatingSet(NormalizeAttempt)
pData(UpdatedGS)
filename <- paste0(Population, "_Norm")

Utility_RidgePlots(gs=UpdatedGS, subset="root", TheY="Specimen", TheFill="Experiment", outpath=NormPath, returntype="pdf", filename = filename, therows = 1)

NormedND <- subset(UpdatedGS, Donor == "NY068")

filename <- paste0(Population, "_Norm_ND006")

Utility_RidgePlots(gs=NormedND, subset="root", TheY="Specimen", TheFill="Experiment", outpath=NormPath, returntype="pdf", filename = filename, therows = 1)
```

### Reverse Biexponential?
```{r}
CS2 <- flowSet_to_cytoset(NormalizeAttempt)
CS2 <- GatingSet(CS2)

PostCytoNorm <- Utility_NbyNPlots(x=CS2[4], sample.name=c("GROUPNAME"), experiment="ABs",
condition="DNs", removestrings=".fcs", marginsubset="root", gatesubset="root", 
ycolumn="PE-Vio770-A", bins=150, clearance=0.1, 
gatelines=FALSE, reference=ShinyGatesSplitpoints2, outpath=StorageLocationForPlotPDF, returntype="patchwork")

PostCytoNorm
```

```{r}
ReversedGS <- transform(NormalizeAttempt, ReverseBiexponential)
```


```{r}
CS3 <- flowSet_to_cytoset(ReversedGS)
CS3 <- GatingSet(CS3)

PostCytoNorm <- Utility_NbyNPlots(x=CS3[4], sample.name=c("GROUPNAME"), experiment="ABs",
condition="DNs", removestrings=".fcs", marginsubset="root", gatesubset="root", 
ycolumn="PE-Vio770-A", bins=150, clearance=0.1, 
gatelines=FALSE, reference=ShinyGatesSplitpoints2, outpath=StorageLocationForPlotPDF, returntype="patchwork")

PostCytoNorm
```


```{r}
ThisWork <- CS3
```

```{r}
NormedNotND <- subset(ThisWork, Donor != "NY068")
pData(NormedNotND)
TheCalcs <- gs_pop_get_stats(NormedNotND, nodes="root", type="count")
min(TheCalcs$count)
# 1000
```

# Out to FCS File

```{r}
Goodbye <- Coereba_Concatenate(Set=NormedNotND, metadata_cols=c("Experiment", "Donor"), outpath="C:/Users/12692/Desktop", filename="DidItWork")
```

```{r}
FCSPath <- file.path("C:/Users/12692/Desktop", "DidItWork.fcs")
TheData <- Coereba::Coereba_FCS_Reversal(Coereba=FCSPath)
# View(TheData)
```


# Generating a Summarized Experiment File

Taking the `Utility_Coereba()` output, we can combine it with metadata and panel information into a SummarizedExperiment object. This will permit us in turn to tie in to a lot of the existing Bioconductor project analysis infrastructure. We do this through the `Coereba_Processing()` function.

We will need to provide a data.frame or a file.path to a csv file containing the panel information. The first column should be called Fluorophore, with the second column the marker name. For our example since we are working with only four markers, we will create and pass this from R. 

```{r}
#| label: Panel Information

ThePanel <- data.frame(
  Fluorophore=c("BUV661", "BV570", "RB780", "PE-Vio770"),
  Marker=c("Vd2", "CD16", "CXCR5", "HLA-DR"))
```

Similar to what we did for `Coereba_GateCutoffs()`, we can have return a csv template containing the specimen names present.

```{r}
MetadataOutpath <- tempdir()

MetadataTemplate <- Coereba_Processing(x=FCSPath, metadataTemplate=TRUE, outpath=MetadataOutpath, panel=ThePanel)

MetadataLocation <- file.path(MetadataOutpath, "Coereba_metadataTemplate.csv")
InitialMetadata <- read.csv(MetadataLocation, check.names=FALSE)

head(InitialMetadata, 5)
```

Now that we have the specimen identifiers, we can append additional metadata utilizing the `left_join()` function from the `dplyr` package, before returning the updated metadata to `Coereba_Processing()`

```{r}
File_Location <- system.file("extdata", package = "Coereba")
StudyMetadataPath <- file.path(File_Location, "SDY3080.csv")
StudyMetadata <- read.csv(StudyMetadataPath, check.names=FALSE)

Specimens <- InitialMetadata |> pull(specimen) |> unique()

# Adding Adult Normalization Controls Not Present in Study Metadata
Specimens <- c(Specimens, "NY068_02", "NY068_03", "NY068_03", "NY068_4",
 "NY068_5", "NY068_6", "NY068_7", "NY068_8")
StudyMetadata <- StudyMetadata |> dplyr::filter(bid %in% Specimens)
StudyMetadata <- StudyMetadata |> rename(specimen=bid)
CoerebaMetadata <- left_join(InitialMetadata, StudyMetadata, by="specimen")
```

```{r}
head(CoerebaMetadata, 5)
```

With the pieces now assembled, we can combine everything into a SummarizedExperiment

```{r}
#| label: Coereba_Processing
TheBioconductor <- Coereba_Processing(x=FCSPath, panel=ThePanel, themetadata=CoerebaMetadata)
```

```{r}
TheBioconductor
```

Using the various Bioconductor accessors, we can see the respective contents. We can see the counts for the individual clusters by specimen. 

```{r}
TheBioconductor@assays@data$count
```

Similar case for the proportions
```{r}
TheBioconductor@assays@data$ratios
```

The expression for each cluster
```{r}
TheBioconductor@elementMetadata
```

The panel
```{r}
TheBioconductor@metadata
```

And the metadata
```{r}
TheBioconductor@colData
```

# Retrieving Marker Expressions

Now that our data is within the SummarizedExperiment, we can carry out different statistical analyses on the individual clusters, or reaggregate them to return summary statistics for the respective markers. For example: 

```{r}
#| label: MarkerExpressions

Data <- Coereba_MarkerExpressions(x=TheBioconductor, returnType="All", theassay="ratios")
  
head(Data, 5)
```

We can alternatively by setting returnType = "Combinatorial" derrive proportions that fall within quadrant gates for two markers of interest.To do this, we provide the fluorophores corresponding to the markers to the CombinatorialArgs.

```{r}
#| label: QuadrantMarkerExpressions
MemoryQuadrants <- Coereba_MarkerExpressions(x=TheBioconductor, theassay="ratios",
 returnType="Combinatorial", CombinatorialArgs = c("BUV661", "RB780"))

head(MemoryQuadrants, 5)
```

From this, we can see that within cord DN T cells, CXCR5 and Vd2 expression do not overlap for the most part. 

# Visualizing Marker Expression with Beeswarm-Boxplots

Having retrieve the marker expression data from the SummarizedExperiment, we can visualize the individual expression of the various markers across all individuals in the form of a beeswarm boxplot, using the `Utility_MarkerPlots()`. These combine both the `r CRANpkg("ggplot2")` geom_boxplot() and `r CRANpkg("ggbeeswarm")` geom_beeswarm plots, with individual dots corresponding to individual specimen. 

To help customize these plots for your particular use case, we provide some arguments to allow for the filtering and reordering of the markers shown in these plots, as well as some basic customizations and the ability to save as a .png. If you want to customize these further, the benefit of open-source software is our code is available, and you are welcome to make as many ggplot2 theme changes as you have time to tinker. 

First thing's first, you will need to specify which metadata column in your data.frame you want to use as factor, and provide the values a desired shape and fill value for each factor level. In the context of our data, we are using factors based on HIV viral and ART exposure, so for our example dataset we would set the values as follows: 

```{r}
#| label: DefiningShapeAndFill 
shape_ptype <- c("HU" = 22, "HEU-lo" = 21, "HEU-hi" = 21)
fill_ptype <- c("HU" = "white", "HEU-lo" = "darkgray", "HEU-hi" = "black")
```

We can start by viewing all markers:

```{r}
#| label: MarkerPlots
#| warning: FALSE

CordOnly <- Data |> dplyr::filter(ptype %in% c("HU", "HEU-lo", "HEU-hi"))

ThePlot <- Utility_MarkerPlots(data=CordOnly, myfactor="ptype", shape_palette = shape_ptype, fill_palette = fill_ptype, panel=ThePanel, XAxisLevels=c("Vd2", "CD16", "CXCR5", "HLA-DR"), cex=3, size =3)
```

```{r}
ThePlot
```

Let's abbreviate the number of columns by specifying the marker names to include (filterForThese), and rearrange them in desired X-axis order

```{r}
#| label: AbbreviatedMarkerPlots
ThePlot <- Utility_MarkerPlots(data=CordOnly, myfactor="ptype", shape_palette = shape_ptype, fill_palette = fill_ptype, panel=ThePanel, cex=4, size =3, filterForThese=c("Vd2", "HLA-DR"), XAxisLevels = c("Vd2", "HLA-DR"))
```

```{r}
#| width: 50%
ThePlot
```

# Statistics

The `Utility_Stats()` and the `Utility_Behemoth()` functions are a a coding-attempt to replicate the typical immunologist workflow, removing the need to copy-paste data from a .csv file to GraphPad Prism or similar software. Behind the scenes, it runs a normaly test, determines number of groups, and follows up with the corresponding t-test/anova/ based on whether parametric or non-parametric. `Utility_Stats()` returns just a data.frame with the statistics, while `Utility_Behemoth()` will return a beeswarm box-plot and display any statistical significant comparisons. Used in combination with `r CRANpkg("purrr")` and `Luciernaga` `Utility_Patchwork()`, we can quickly pipe our data through to a .pdf file that we can quickly scroll through. 

Does this approach save a lot of time? Yes. Are there caveats? Absolutely. With the ability to rapidly screen thousands of differential comparisons, we are essentially mining our haystacks for needles. Not every hit will actually be a needle, and the caveats that are associated with each test become meaningful to understand. Please use these functions responsibly, and check out the Statistical Rethinking series by Richard McElreath on YouTube.

# Utility Statistics

Having retrieved a now tidyed data.frame using `Coereba_MarkerExpressions`, let's switch from visualization to runnning statistical test with `Utility_Stats()` for each of the markers. 

```{r}
#| label: Utility_Stats
Result <- Utility_Stats(data=CordOnly, var="HLA-DR",
  myfactor="infant_sex", normality="dagostino", correction="none")

Result
```

Rather than specifying each marker, we can leverage functional programming functions within the `r CRANpkg("purrr")` to quickly check all markers using common statistical tests. We will need to skip over the metadata columns that are present at the begining of the dataframe, so let's identify where these end. 

```{r}
TheLength <- ncol(CordOnly)
colnames(CordOnly)
```

With that done, we can now run provide the index to our factor of interest and all other non-metadata columns.

```{r}
#| label: Utility_Stats purrr map

TheData <- map(names(CordOnly)[c(4:TheLength)], ~ Utility_Stats(
  data = CordOnly, var = .x, myfactor = "infant_sex", 
  normality = "dagostino")) |> bind_rows()
```

The results can be filtered using regular `r CRANpkg("dplyr")` functions. Nothing was statistically significant for this particular example, so I will set the pvalue at 0.3 to demonstrate the filtering

```{r}
#| label: Filtering Statistically Significant Hits

MaybeSignificant <- TheData |> dplyr::filter(pvalue < 0.3)

MaybeSignificant
```


# Utility_Behemoth

An extension to `Utility_Stats()`, the `Utility_Behemoth()` function will append the resulting p-value information onto a ggplot2 plot to allow us to visualize the underlying data. It's plots are a combination of  `r CRANpkg("ggplot2")` `geom_boxplot()` and `r CRANpkg("ggbeeswarm")` `geom_beeswarm()` plots. We have also provisioned the function to accept arguments to customize these and rearrange the group order. As with most `Coereba` plots, we will need to provide the shape and fill for our respective factors levels. If you miss a listing a level, these will not appear in the plot (but still impact the axis scaling, resulting in a warning)

```{r}
#| label: Shape Fill Sex
shape_sex <- c("Female" = 22, "Male" = 21)
fill_sex <- c("Female" = "white", "Male" = "black")
```

To do so for your own individual spots, you will need to specify a metadata column by which to factor by, and provide a list of shape and fill values corresponding to each factor level. 

```{r}
#| label: Utility_Behemoth
SinglePlot <- Utility_Behemoth(data=CordOnly, var="HLA-DR",
  myfactor="infant_sex", normality="dagostino", correction="none",
  shape_palette=shape_sex, fill_palette=fill_sex,
  XAxisLevels = c("Female", "Male"))
```

```{r}
SinglePlot
```

As was the case with `Utility_Stats()`, when combined with the `r CRANpkg("purrr")` package we can rapidly iterate over all the markers (skipping the initial metadata colums) and generate all the plots. 

```{r}
#| label: purrring behemoth
#| warning: FALSE


# colnames(AllMarkers)
TheLength <- length(CordOnly)

AllPlots <- map(names(CordOnly)[c(4:TheLength)], ~ Utility_Behemoth(data=CordOnly, var=.x,
  myfactor="infant_sex", normality="dagostino", correction="none",
  shape_palette=shape_sex, fill_palette=fill_sex, corral.width=0.7,
  XAxisLevels = c("Female", "Male")))
```

```{r}
#| width: 50%
AllPlots
```

These plots in turn can then be passed to `Luciernaga` `Utility_Patchwork()` to our desired layout, and subsequently exported out as a .pdf file for analysis. 

```{r}
#| label: Utility_Patchwork
TheAssembledPlot <- Utility_Patchwork(x=AllPlots, filename="CordBloodDNTcells",
 outfolder=StorageLocation, thecolumns=2, therows=2, width=7, height=9,
 returntype="patchwork")
```

```{r}
TheAssembledPlot[1]
```

```{r}
StorePDFHere <- file.path("C:", "Users", "JohnDoe", "Desktop")

StorePDFHere <- tempdir()

TheAssembledPlot <- Utility_Patchwork(x=AllPlots, filename="CordBloodDNTcells",
 outfolder=StorePDFHere, thecolumns=2, therows=2, width=7, height=9,
 returntype="pdf")
```


```{r sessionInfo}
#| echo: FALSE
sessionInfo()
```
