---
title: "Using Coereba"
package: Coereba
author:
- name: David Rach
  email: drach@som.umaryland.edu
  affiliation: University of Maryland, Baltimore
date: "`r BiocStyle::doc_date()`"
format:
  html:
    minimal: true
    theme: flatly
vignette: |
  %\VignetteIndexEntry{Workflow}
  %\VignetteKeywords{Workflow}
  %\VignettePackage{Coereba}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{quarto::html}
  %\VignetteDepends{BiocStyle}
---

```{r}
#| eval: FALSE
knitr::opts_chunk$set(
  eval = FALSE,
  collapse = TRUE,
  comment = "#>"
)
```

```{r}
#| label: BackgroundLibraryLoadForVignette
#| echo: FALSE
#| warning: FALSE
#| results: "hide"

suppressPackageStartupMessages({
library(Coereba)
library(BiocStyle)
library(flowCore)
library(flowWorkspace)
library(CytoML)
library(openCyto)
library(ggcyto)  
library(data.table)
library(dplyr)
library(purrr) 
library(stringr)
library(ggplot2)
library(gt)
#library(plotly)
#library(htmltools)
})
```

# Setup

## Installing Coereba

We are in the process of preparing Coereba to submit to Bioconductor later this year. Until then, the developmental version can be installed via GitHub.

```{r}
#| label: "Installing Coereba"
#| eval: FALSE

if(!require("remotes")){install.packages("remotes")}
remotes::install_github("https://github.com/DavidRach/Coereba")

# install.packages("BiocManager")
# BiocManager::install("Coereba")
```

## Load Required Libraries

Coereba primarily relies on the infrastructure provided `r Biocpkg("flowWorkspace")` and other Bioconductor cytometry R packages. It additionally leverages various `r CRANpkg("tidyverse")` packages available via CRAN. Before starting, it is important to make sure all required packages are first installed, and that library is called for each to make them available. 

```{r}
#| label: "Load Libraries"

# CRAN packages: install.packages("ThePackageName")

# library(dplyr)
# library(purrr) 
# library(stringr)
# library(ggplot2)
# library(gt)
# library(plotly)
# library(htmltools)
# library(data.table)

# Bioconductor packages: BiocManager::install("ThePackageName")

library(Coereba)
#library(flowCore)
#library(flowWorkspace)
#library(openCyto)
#library(ggcyto)  

```

## Locate your files

You will next need to provide to your computer the location where your .fcs files of interest are stored. An example of how the author does this for the various computer operating systems is shown below. Please modify the file.paths accordingly to match your own username and folder location.

```{r}
#| label: "File Paths"
#| eval: FALSE

# For Windows Operating Systems

File_Location <- file.path("C:", "Users", "JohnDoe", "Desktop", "TodaysExperiment")
FCS_Pattern <- ".fcs$"
FCS_Files <- list.files(path = File_Location, pattern = FCS_Pattern,
                        full.names = TRUE, recursive = FALSE)

# For Mac

# For Linux
# File_Location <- file.path("/home", "JohnDoe", "Desktop", "TodaysExperiment")
```

For this vignette, we will be utilizing several .fcs files that are stored within Coereba's extdata folder. These consist of unmixed .fcs files from a 32 fluorophore Spectral Flow Cytometry panel. We manually gated down to CD4-CD8- (DN) T cells, from which we downsampled up to 1000 cells to create a sufficiently small dataset to use for the R package documentation. 

```{r}
#| label: "Accessing Coereba's FCS files"
File_Location <- system.file("extdata", package = "Coereba")
FCS_Pattern <- ".fcs$"
FCS_Files <- list.files(path = File_Location, pattern = FCS_Pattern,
                        full.names = TRUE, recursive = FALSE)
head(FCS_Files, 3)
```

 

## Creating a GatingSet

### flowWorkspace and openCyto

Working with the unmixed .fcs files we have identified above, we will group them into a GatingSet object where we can further interact with them.

```{r}
#| label: GatingSet
UnmixedFCSFiles <- FCS_Files
UnmixedCytoSet <- load_cytoset_from_fcs(UnmixedFCSFiles, truncate_max_range = FALSE,
                                        transformation = FALSE)
UnmixedGatingSet <- GatingSet(UnmixedCytoSet)
UnmixedGatingSet
```

Now that we have created a GatingSet object, we will generate list of the fluorophores and markers present. We will then exclude from this list markers that don't require transformation (FSC, SSC, etc.) For this example, we will biexponentially transform our data using the `r Biocpkg("flowWorkspace")` `flowWorkspace::flowjo_biexp_trans()`.

```{r}
#| label: "Biexponential Transformation"
#| message: false
Markers <- colnames(UnmixedCytoSet)
KeptMarkers <- Markers[-grep("Time|FS|SC|SS|Original|-W$|-H$|AF", Markers)]

MyBiexponentialTransform <- flowjo_biexp_trans(channelRange = 256, maxValue = 1000000,
                                               pos = 4.5, neg = 0, widthBasis = -1000)
TransformList <- transformerList(KeptMarkers, MyBiexponentialTransform)
UnmixedGatingSet <- transform(UnmixedGatingSet, TransformList)
```

For this example, we will apply a `r Biocpkg("openCyto")`gating template that can be found in the extdata folder to apply a gate to distinguish Vdelta2 cells from other DN T cells. 

```{r}
#| label: "openCyto Gating"
UnmixedGates <- fread(file.path(path = File_Location, pattern = 'GatesUnmixed.csv'))
UnmixedGating <- gatingTemplate(UnmixedGates)
gt_gating(UnmixedGating, UnmixedGatingSet)
```

```{r}
plot(UnmixedGatingSet)
```

We can additionally verify that the gating of the cell populations of interest was correct, by visualizing the gates using `r Biocpkg("ggcyto")` or the `Luciernaga::Utility_GatingPlots` function from the `Luciernaga` package. 

```{r}
#| label: "Checking the openCyto gate"
library(Luciernaga)

MyPlot <- Utility_GatingPlots(x=UnmixedGatingSet[4], sample.name=c("GROUPNAME", "TUBENAME"),
                              removestrings=".fcs", subset="root", gtFile=UnmixedGates,
                              DesiredGates=NULL, returnType="plots", outpath = getwd(),
                              therows=1, thecolumns=2)

MyPlot
```

### CytoML

An alternative approach to creating a new GatingSet with `r Biocpkg("openCyto")`, would to be to import an existing FlowJo workspace using `r Biocpkg("CytoML")`. The workflow for this approach would look something as follows:

```{r}
#| label: "CytoML example"
#| eval: FALSE

# For Windows Operating Systems
folder <- file.path("C:", "Users", "JohnDoe", "Desktop", "TodaysExperiment")
wsp <- list.files(pattern=".wsp", full.names=TRUE)
```

```{r}
#| label: BackgroupWspLoadForVignette
#| echo: FALSE
#| warning: FALSE
#| results: "hide"
folder <- system.file("extdata", package = "Coereba")
wsp <- list.files(folder, pattern=".wsp", full.names=TRUE)
```

```{r}
#| label: CytoML workflow
library(CytoML)
ws <- open_flowjo_xml(wsp[1])
CytoML_GS <- flowjo_to_gatingset(ws, name=1, path = folder, additional.keys="GROUPNAME")
CytoML_GS
```

```{r}
#| label: Checking CytoML output
library(Luciernaga)

MyPlot <- Utility_GatingPlots(x=CytoML_GS[27], sample.name=c("GROUPNAME", "TUBENAME"),
                              removestrings=".fcs", subset="root", gtFile=UnmixedGates,
                              DesiredGates=NULL, returnType="plots", outpath = getwd(),
                              therows=1, thecolumns=2)

MyPlot
```

# Coereba

Having set up a GatingSet and applied the transformations and gates, we can now proceed to the main `Coereba` workflow. 

For this example, we will focus on just 4 of the 32 markers, CD16 (BV570), CXCR5 (RB780), HLA-DR(PE-Vio770), and Vdelta2 (BUV661). Most cord DN T cells are negative for these markers, but 5-25% are positive, so they are good examples to showcase the gate adjustment mechanisms. The process when working with all 32-markers is similar, but will take a little more compute time. 

```{r}
#| label: Designating markers

# BV570=CD16, RB780=CXCR5, BUV661=Vd2, PE-Vio770=HLA-DR

MarkersForToday <- c("Comp-BV570-A", "Comp-RB780-A", "Comp-BUV661-A", "Comp-PE-Vio770-A")
```


## Return a Coereba Gate cutoff template

The first step is to create a .csv file, containing the individual specimens, and the individual markers of interest. Each cell within the .csv file will correspond to the MFI for a given marker for a given individual where positive expression of a marker transitions to becoming a negative (referred here to as a splitpoint). 

These could be specified out individually, or derrived in an automated fashion. In Coereba, we leverage the `r Biocpkg("openCyto")` automated gating functions (primarily the gate_mindensity option) to save us from the eye-strain of typing everything out. We will run the `Coereba_GateCutoffs()` function on each specimen in the GatingSet, and use the `r CRANpkg("dplyr")` packages `bind_rows()`to gather the rows into a data.frame object. We in turn can save this as a .csv for later use (or minor hand editing). 

```{r}
# Designate a location file.path to save the calculated splitpoints .csv to. 
StorageLocationForSplitpoints <- file.path("C:", "Users", "JohnDoe", "Desktop")

# We will use a temp() folder for this documentation example. 
StorageLocationForSplitpoints <- tempdir()

TheGateCutoffs <- purrr::map(.x=UnmixedGatingSet, .f=Coereba_GateCutoffs,
  subset="root", sample.name=c("GROUPNAME"), desiredCols=MarkersForToday) |> bind_rows()

TheFileName <- file.path(StorageLocationForSplitpoints, "InitialGates.csv")

write.csv(TheGateCutoffs, TheFileName, row.names=FALSE)
```

```{r}
TheGateCutoffs
```

With these intial split points calculated, we can visualize how well the splitpoints were calculated by plotting them as red-lines using the `Luciernaga` packages `Utility_NbyNPlots()` (visualizing all marker combinations for an individual specimen) and `Utility_UnityPlots()` (visualizing a marker combination across all specimens) functions. The resulting plots can be returned to R using either the returntype= "plots" or "patchwork" arguments, or saved to the directory by providing the "pdf" argument instead. 

```{r}
#| label: NbyN plot check
#| message: FALSE
#| warning: FALSE

# Designate a location
StorageLocationForPlotPDF <- file.path("C:", "Users", "JohnDoe", "Desktop")

# We will use a temp() folder for this documentation example. 
StorageLocationForPlotPDF <- tempdir()

Plot <- Utility_NbyNPlots(x=UnmixedGatingSet[4], sample.name=c("GROUPNAME"), experiment="ABs",
condition="DNs", removestrings=".fcs", marginsubset="root", gatesubset="root", 
ycolumn="Comp-PE-Vio770-A", bins=150, clearance=0.1, 
gatelines=TRUE, reference=TheGateCutoffs, outpath=StorageLocationForPlotPDF, returntype="patchwork")
```

When a marker has distinct positive or negative markers, the initial estimated location works well. 

```{r}
Plot
```

However, when everything is uniformly positive or negative, or more subtle shift, these estimated locations can be quite off, and the respective splitpoints will need to be corrected. If a particular marker(s) is consistently off, we can redo the splitpoints for individual markers by providing gate_range arguments to constrain the mindensity to searching within a particular area. 

The simplest way to do this is to set the `Coereba_GateCutoffs()` returnTemplate argument to TRUE, which will return a TemplateForGates.csv based off the openCyto template .csv.

```{r}
#| label: Return an openCyto template

# Designate a location file.path to save the template to. 
StorageLocationForTemplate <- file.path("C:", "Users", "JohnDoe", "Desktop")

# We will use a temp() folder for this documentation example. 
StorageLocationForTemplate <- tempdir()

ReturnATemplate <- Coereba_GateCutoffs(x=UnmixedGatingSet[1],
  subset="root", sample.name="GROUPNAME", desiredCols=MarkersForToday, 
  returnTemplate=TRUE, outpath=StorageLocationForTemplate)   
```

```{r}
TheTemplate <- list.files(StorageLocationForTemplate,
 pattern="TemplateForGates.csv", full.names=TRUE)

TheTemplateCSV <- read.csv(TheTemplate, check.names=FALSE)
```

```{r}
#| echo: FALSE
TheTemplateCSV
```

We can then manually update with the gate_range arguments. 

```{r}
#On your own workstation

UpdatedTemplatePath <- file.path("C:", "Users", "JohnDoe", "Desktop",
"UpdatedTemplateForGates.csv")

# For our documentation's example

folder <- system.file("extdata", package = "Coereba")

UpdatedTemplatePath <- list.files(folder, pattern="UpdatedTemplateForGates.csv", full.names=TRUE)

UpdatedTemplate <- read.csv(UpdatedTemplatePath, check.names=FALSE)
```

```{r}
UpdatedTemplate
```

With this done, we can provide it back to `Coereba_GateCutoffs()` with the GateOverwrite argument set to TRUE. This will restart the calculation of the splitpoints.

```{r}
TheUpdatedGateCutoffs <- purrr::map(.x=UnmixedGatingSet, .f=Coereba_GateCutoffs,
  subset="root", sample.name="GROUPNAME", desiredCols=MarkersForToday,
  GatingTemplate=UpdatedTemplatePath, GateOverwrite=TRUE) %>% bind_rows()

# Designate a location file.path to save the template to. 
StorageLocationForUpdatedSplitpoints <- file.path("C:", "Users", "JohnDoe", "Desktop")

# We will use a temp() folder for this documentation example. 
StorageLocationForUpdatedSplitpoints <- tempdir()

SecondGates <- file.path(StorageLocationForUpdatedSplitpoints, "SecondGates.csv")
write.csv(TheUpdatedGateCutoffs, SecondGates, row.names=FALSE)
```

```{r}
TheUpdatedGateCutoffs
```

This ultimately allows the splitpoint gate estimates to be closer to the true positive/negative split, resulting in less total adjustments that need to be done via the Coereba Shiny app.

```{r}
#| label: NbyN plot check 2
#| message: FALSE
#| warning: FALSE

StorageLocationForPlotPDF <- tempdir()

UpdatedPlot <- Utility_NbyNPlots(x=UnmixedGatingSet[4], sample.name=c("GROUPNAME"), experiment="ABs",
condition="DNs", removestrings=".fcs", marginsubset="root", gatesubset="root", 
ycolumn="Comp-PE-Vio770-A", bins=150, clearance=0.1, 
gatelines=TRUE, reference=TheUpdatedGateCutoffs, outpath=StorageLocationForPlotPDF, returntype="patchwork")
```

```{r}
UpdatedPlot
```

## Coereba_App

With the estimated splitpoints having been calculated, we still need to make sure to correct the location for the odd specimen that is of. We have created a R Shiny App to facilitate this process. When provided with the .csv of splitpoints, it will load in the GatingSet object, and plot an interactive version of `Utility_UnityPlot()` from the `Luciernaga` package, visualizing the splitpoint for a given marker across all individuals as red vertical lines. These can then be updated via the graphical user interface (GUI) by clicking just above the axis. 

First off, remember the location you saved the splitpoints .csv, as the Shiny App will ask you to find it later:

```{r}
#| label: Remembering Storage Location

# Wherever you stored it
File_Location <- file.path("C:", "Users", "JohnDoe", "Desktop")

# For our example documentation
File_Location <- system.file("extdata", package = "Coereba")
TheCSV <- file.path(File_Location, "SecondGates.csv")
TheCSVData <- read.csv(TheCSV, check.names=FALSE)
head(TheCSVData)
```

Similarly, make sure to remember what you called your GatingSet ("UnmixedGatingSet" for our example), and the sample.name keyword used to identify individual specimens, as you will need to also provide these values to the app.

We will now launch the Shiny App by calling the `Coereba_App()` function

```{r}
#| label: Coereba_App
#| eval: false

#library(DT)
#library(plotly)
#library(shiny)
#library(shinydashboard)

Coereba_App()
```

Upon launch, you land inside the Upload CSV File tab (located on the upper left). Go ahead and click on the Import .csv button.   

![](`r system.file("extdata", "ShinyLanding.png", package = "Coereba")`){width="75%"}

Proceed to find and upload your SecondGates.csv equivalent (containing the updated splitpoints based on the gate_range constraints) by navigating to the storage folder location and select it. Once done, the contents will appear in the space on the right.

![](`r system.file("extdata", "ShinySplitpointsLoaded.png", package = "Coereba")`){width="75%"}

Next, you will select the "Upload a Gating Set" tab on the upper left.

What we now see is a way to provide arguments to the interactive version of `Utility_UnityPlots()`

Enter the information about your GatingSet ("UnmixedGatingSet" for this example), select your desired x and y parameters ("Comp-BUV661-A", etc), and the Sample.Name keyword that designates the respective specimens. The bins argument will adjust how th cells are visualized, with higher numbers being finer detail. Clearance is a proportion used to create additional space around the edge of the plot, which is set based on the values for the respective subset provided by the margin argument. The cells being plotted come from the "gate" subset box.  Finally, click Display Estimated Gate Cutoffs to visualize the splitpoints as vertical red lines.  

![](`r system.file("extdata", "ShinyDetailsLoaded.png", package = "Coereba")`){width="75%"}

Once this is done, click Generate Plots. If you view the console of the main R session, you will see the Utility_NbyNplot messages running as the plots are generated. How long it will take to load in the plots depends on the number of specimens, and the size of the files. Once the plots are loaded, wait a couple of seconds until you can hover with your mouse over the plots before clicking to avoid having the App freeze up. 

![](`r system.file("extdata", "ShinyVisuals.png", package = "Coereba")`){width="75%"}

For standard workflow, scroll examining how the splitpoints were assigned for the individual samples. When you encounter a splitpoint line that was incorrectly set, hover just above the just above the x-axis for the correct location, and click on the spot with your mouse (see blue arrow for an example). 

![](`r system.file("extdata", "ShinyUpdating.png", package = "Coereba")`){width="75%"}

When you click just above the axis for the corrected splitpoint, you should see a click event captured message pop up in the console window of the Main R environment. If you click to far above the axis, you will not see this message displayed. Similarly, this message can be used to remember at what sample you left off when scrolling. All these clicks will save the coordinate as a splitpoint for that given marker and individual to a data.frame we will see on the next tab. 

In terms of accidentally clicking the wrong location, only the last click for a respective sample will be used, so in case of a misclick, reclick on the correct location. 

![](`r system.file("extdata", "ConsoleClicks.png", package = "Coereba")`){width="75%"}

Once you have corrected everything for a particular marker, switch down to the next x-axis marker, and regenerate the plots. Once they are loaded, proceed to correct the splitpoints for each additional marker.

![](`r system.file("extdata", "CorrectSplitpoints.png", package = "Coereba")`){width="75%"}

Once this is complete, navigate to the Click Data tab on the upper left. You will see the click events in their totality. You will next need to export this data. 

![](`r system.file("extdata", "ClickDataExport.png", package = "Coereba")`){width="75%"}

Due to computer safety reasons, Shiny Apps are not allowed to write directly to your computer file system. So you will need to manually type in the file name and the file.path to a storage location. Once this is done, click "Export Click Data". If this was done successfully, you should see the following notice appear. 

![](`r system.file("extdata", "CheckoutNotice.png", package = "Coereba")`){width="75%"}

Finally, close out of the Shiny window, and hit the red stop button on the right-hand of the console to return back to Positron. 

When working with a large dataset, we have observed the ShinyApp start to slow after a couple markers. When this occurs, save the click file to your destination folder, close the ShinyApp, and relaunch. Correct a couple additional markers, and save the Export Click Data again with a different name. After everything is gated, the same function used to update the Splitpoint.csv can be used to grab all .csv files from within a folder in a single go. 
 
(Note for developers: Shiny relies heavily on reactive R, which is not the maintainer's coding forte, so some additional work to speed things up behind the scenes is likely required. If this is your area of expertise, feel free to contribute!)


# Updating the Splitpoints

Having gone through and corrected the splitpoints with `Coereba_App()`, it is time to convert your validated click-data and update the SecondGates.csv to reflect the changes. To facilitate this, we will use the `Coereba_UpdateGates()` function. This can be used to update for either a single click-data .csv, or the file.path to the folder containing all the click-data .csv files in one go.

In our case, we will update using the saved click-data from above stored inside the extdata folder. 
```{r}
# Wherever you stored it
File_Location <- file.path("C:", "Users", "JohnDoe", "Desktop")

# For our example documentation
File_Location <- system.file("extdata", package = "Coereba")
TheOldCSV <- file.path(File_Location, "SecondGates.csv")
TheClickInfo <- file.path(File_Location, "CorrectSplitpointLocations.csv")
TheClickData <- read.csv(TheClickInfo, check.names=FALSE)
TheClickData
```

By comparison, the data from SecondGates that will be updated
```{r}
TheOldData <- read.csv(TheOldCSV, check.names=FALSE)
TheOldData
```

We can then run `Coereba_UpdateGates()` and examine how the PE-Vio770 values are correspondingly updated.

```{r}
ShinyGatesSplitpoints <- Coereba_UpdateGates(Clicks=TheClickInfo, Old=TheOldCSV,
  export=FALSE, outpath=NULL, fileName="UpdatedCSV")

ShinyGatesSplitpoints
```

```{r}
# Designate a location file.path to save the Shiny Updated Splitpoints to
StorageLocationForShinyUpdatedSplitpoints <- file.path("C:", "Users", "JohnDoe", "Desktop")

# We will use a temp() folder for this documentation example. 
StorageLocationForShinyUpdatedSplitpoints <- tempdir()

ShinyGatesPath <- file.path(StorageLocationForShinyUpdatedSplitpoints, "ShinyGates.csv")
write.csv(ShinyGatesSplitpoints, ShinyGatesPath, row.names=FALSE)
```

We in turn can validate this further by  by re-running `Luciernaga` `Utility_NbyNPlots()` or `Utility_UnityPlots()` using the updated GateCutoff.csv and see how things look now following our intervention. 

```{r}
#| label: NbyN plot check 3
#| message: FALSE
#| warning: FALSE

StorageLocationForPlotPDF <- tempdir()

UpdatedPlotAfterShiny <- Utility_NbyNPlots(x=UnmixedGatingSet[4], sample.name=c("GROUPNAME"), experiment="ABs",
condition="DNs", removestrings=".fcs", marginsubset="root", gatesubset="root", 
ycolumn="Comp-PE-Vio770-A", bins=150, clearance=0.1, 
gatelines=TRUE, reference=ShinyGatesSplitpoints, outpath=StorageLocationForPlotPDF, returntype="patchwork")
```

```{r}
UpdatedPlotAfterShiny
```

# Coereba

With the gate locations now finalized, it's time to run Coereba and classify each individual cell within  a specimen by it's marker expression relative to their respective splitpoint location. Cells that share marker expressions ultimately end up in the same clusters. We will use the `Utility_Coereba()` function for this process, providing both the validated ShinyGates and our GatingSet.  

```{r}
#| label: Utility_Coereba

# Wherever you stored it
File_Location <- file.path("C:", "Users", "JohnDoe", "Desktop")

# For our example documentation
File_Location <- system.file("extdata", package = "Coereba")

CheckedGates <- file.path(File_Location, "ShinyGates.csv")

CoerebaData <- Utility_Coereba(gs=UnmixedGatingSet, subsets="root",
 sample.name="GROUPNAME", reference=CheckedGates, starter="Comp-PE-Vio770-A",
 inverse.transform = TRUE, returnType="data", Individual=FALSE, outpath=NULL,
 columns = MarkersForToday)
```

```{r}
head(CoerebaData)
```

In the above case, we set returnType = "data", and Individual = "FALSE", resulting in a single data.frame containing the content for all specimens.  Please refer to the documentation for `Utility_Coereba()` for additional options. 


# Save to FCS file (optional)

Once `Utility_Coereba()` has been run, we can send the output to an .fcs file. In this process, any metadata present will be converted over to numeric keyword format, with the actual information stored away as keywords for later retrieval. Exporting as an .fcs can can be useful when we are planning to export to an .fcs file for downstream unsupervised analysis, as it allows us to run dimensionality visualization algorithms, gate the islands, and then retrieve Coereba data as far as gating and metadata from cells within those respective islands. 

```{r}
#| label: Coereva_FCSExport

# Designate a location file.path to save the Shiny Updated Splitpoints to
StorageLocationForFCS <- file.path("C:", "Users", "JohnDoe", "Desktop")

# We will use a temp() folder for this documentation example. 
StorageLocationForFCS <- tempdir()

FCSFile <- Coereba::Coereba_FCSExport(data=CoerebaData, gs=UnmixedGatingSet[1],
      returnType="fcs", outpath=StorageLocationForFCS, filename="CoerebaTest",
      nameAppend="", Aggregate=FALSE)
```

Likewise, once we are done with the unsupervised analysis, we can retrieve the same data back to R through the `Coereba_FCS_Reversal()` function. 

```{r}
#| label: Coereba_FCS_Reversal
FCSPath <- file.path(StorageLocationForFCS, "CoerebaTest.fcs")
RetrievedData <- Coereba::Coereba_FCS_Reversal(Coereba=FCSPath)
# View(RetrievedData)
```

```{r}
RetrievedData
```

# Generating a Summarized Experiment File

Taking the `Utility_Coereba()` output, we can combine it with metadata and panel information into a SummarizedExperiment object. This will permit us in turn to tie in to a lot of the existing Bioconductor project analysis infrastructure. We do this through the `Coereba_Processing()` function.

We will need to provide a data.frame or a file.path to a csv file containing the panel information. The first column should be called Fluorophore, with the second column the marker name. For our example since we are working with only four markers, we will create and pass this from R. 

```{r}
#| label: Panel Information

ThePanel <- data.frame(Fluorophore=c("BUV661", "BV570", "RB780", "PE-Vio770"),
  Marker=c("Vd2", "CD16", "CXCR5", "HLA-DR"))
```

Similar to what we did for `Coereba_GateCutoffs()`, we can have return a csv template containing the specimen names present.

```{r}
MetadataOutpath <- tempdir()

MetadataTemplate <- Coereba_Processing(x=FCSPath, metadataTemplate=TRUE, outpath=MetadataOutpath, panel=ThePanel)

MetadataLocation <- file.path(MetadataOutpath, "Coereba_metadataTemplate.csv")
InitialMetadata <- read.csv(MetadataLocation, check.names=FALSE)

head(InitialMetadata, 5)
```

Now that we have the specimen identifiers, we can append additional metadata utilizing the `left_join()` function from the `dplyr` package, before returning the updated metadata to `Coereba_Processing()`

```{r}
File_Location <- system.file("extdata", package = "Coereba")
StudyMetadataPath <- file.path(File_Location, "SDY3080.csv")
StudyMetadata <- read.csv(StudyMetadataPath, check.names=FALSE)

Specimens <- InitialMetadata |> pull(specimen) |> unique()

# Adding Adult Normalization Controls Not Present in Study Metadata
Specimens <- c(Specimens, "NY068_02", "NY068_03", "NY068_03", "NY068_4",
 "NY068_5", "NY068_6", "NY068_7", "NY068_8")
StudyMetadata <- StudyMetadata |> filter(bid %in% Specimens)
StudyMetadata <- StudyMetadata |> rename(specimen=bid)
CoerebaMetadata <- left_join(InitialMetadata, StudyMetadata, by="specimen")
```

```{r}
head(CoerebaMetadata, 5)
```

With the pieces now assembled, we can combine everything into a SummarizedExperiment

```{r}
#| label: Coereba_Processing
TheBioconductor <- Coereba_Processing(x=FCSPath, panel=ThePanel, themetadata=CoerebaMetadata)
```

```{r}
TheBioconductor
```

Using the various Bioconductor accessors, we can see the respective contents. We can see the counts for the individual clusters by specimen. 

```{r}
TheBioconductor@assays@data$count
```

Similar case for the proportions
```{r}
TheBioconductor@assays@data$ratios
```

The expression for each cluster
```{r}
TheBioconductor@elementMetadata
```

The panel
```{r}
TheBioconductor@metadata
```

And the metadata
```{r}
TheBioconductor@colData
```

# Retrieving Marker Expressions

Now that our data is within the SummarizedExperiment, we can carry out different statistical analyses on the individual clusters, or reaggregate them to return summary statistics for the respective markers. For example: 

```{r}
#| label: MarkerExpressions

Data <- Coereba_MarkerExpressions(x=TheBioconductor, returnType="All", theassay="ratios")
  
Data
```

We can alternatively by setting returnType = "Combinatorial" derrive proportions that fall within quadrant gates for two markers of interest.To do this, we provide the fluorophores corresponding to the markers to the CombinatorialArgs.

```{r}
#| label: QuadrantMarkerExpressions
MemoryQuadrants <- Coereba_MarkerExpressions(x=TheBioconductor, theassay="ratios",
 returnType="Combinatorial", CombinatorialArgs = c("BUV661", "RB780"))

MemoryQuadrants
```

From this, we can see that within cord DN T cells, CXCR5 and Vd2 expression do not overlap for the most part. 

# Marker Expression Beeswarm plots

Having retrieved the Marker expression data, we can visualize all the markers at one against a factor of interest in the form of a beeswarm-box plot. 
Having returned aggregated data above with `Coereba_MarkerExpressions`, we can plot this data using `Utility_MarkerPlots()`. These are combination of `r CRANpkg("ggplot2")` geom_boxplot() and `r CRANpkg("ggbeeswarm")` geom_beeswarm plots. We provide some arguments that allow for filtering and reordering the markers shown in these plots, some basic customizations to the plots, and the ability to save as a .png file to a designated folder. 

To do so for your own individual spots, you will need to specify a metadata column by which to factor by, and provide a list of shape and fill values corresponding to each factor level. 

```{r}
#| label: DefiningShapeAndFill 
#| eval: FALSE
shape_ptype <- c("HU" = 22, "HEU-lo" = 21, "HEU-hi" = 21)
fill_ptype <- c("HU" = "white", "HEU-lo" = "darkgray", "HEU-hi" = "black")
```

We can start by viewing all markers:

```{r}
#| label: MarkerPlots
#| eval: FALSE


ThePlot <- Utility_MarkerPlots(data=AllMarkers, panel=panelData,
  myfactor="ptype", shape_palette = shape_ptype, fill_palette = fill_ptype)

ThePlot
```

Let's abbreviate the number of columns by specifying the marker names to include (filterForThese), and rearrange them in desired X-axis order

```{r}
#| label: AbbreviatedMarkerPlots
#| eval: FALSE
ThePlot <- Utility_MarkerPlots(data=AllMarkers, panel=panelData,
  myfactor="ptype", shape_palette = shape_ptype, fill_palette = fill_ptype,
  filterForThese=c("CD7", "CD4", "CD8"), XAxisLevels = c("CD7", "CD4", "CD8"))

ThePlot
```

And to ggsave directly to a desired folder:

```{r}
#| eval: FALSE
print("Hello")
```


# Marker Expression Heatmap

Another way to summarize the data from the Marker expression plots is in the form of a heatmap. To do this, we can take the retrieved marker expression data and pass it along to the function. 

# Utility Statistics

We can leverage functional programming, and retrieve back results of a t-test or one-way anove for all our columns. 

The `Utility_Stats()` and the `Utility_Behemoth()` functions are either: "Great!!!", or guaranteed to make your friendly-local statistician cry (Opinions vary). 

Basically, `Utility_Stats()` is a coding-attempt to replicate the typical immunologist workflow, cutting out the need to copy-paste data from a .csv file into GraphPad Prism (trademark), run a normality test, determine number of groups, and follow up with the corresponding t-test/anova/non-parametric equivalents. `Utility_Behemoth()` then takes these outputs, and adds the p-value results to a ggbeeswarm/ggplot2 boxplot of the underlying data. In combination with `r CRANpkg("purrr")` and `Luciernaga` `Utility_Patchwork()`, these can be quickly formatted into a .pdf. 

Does this workflow rapidly profile all the columns in your data.frame. Yes it does. Is it emblematic of potential issues arising from basing science entirely on null-hypothesis statistical testing? Also yes, seeing how many plots return "significant" due to a couple outliers. In the end, it mimics the current workflow of many researchers, just speeding it up. Google Statistical Rethinking on YouTube for food-for-thought.

To begin, we will use the `Coereba_MarkerExpressions` data we generated above to test out `Utility_Stats()`. 

```{r}
#| eval: FALSE
Result <- Utility_Stats(data=AllMarkers, var="CD62L",
  myfactor="ptype", normality="dagostino", correction="none")

Result
```

In combination with `r CRANpkg("purrr")` we can rapidly iterate over all the markers, but will need to skip over the metadata columns that are present at the begining of the dataframe. 

```{r}
#| eval: FALSE
library(purrr)
library(dplyr)
# colnames(AllMarkers)
TheLength <- ncol(AllMarkers)

TheData <- map(names(AllMarkers)[c(9:TheLength)], ~ Utility_Stats(
  data = AllMarkers, var = .x, myfactor = "ptype", 
  normality = "dagostino")) %>% bind_rows()
```

The results can be filtered using regular `r CRANpkg("dplyr")` functions.

```{r}
#| eval: FALSE
MaybeSignificant <- TheData %>% dplyr::filter(pvalue < 0.05)

MaybeSignificant
```


# Utility_Behemoth

We can take Utility_Statistics one step further and similarly send the outputted plots to a pdf for quick scanning

`Utility_Behemoth()` continues from where `Utility_Stats()` left-off, appending the resulting p-value information onto a ggplot2 plot. The plot is a combination of `r CRANpkg("ggplot2")` geom_boxplot() and `r CRANpkg("ggbeeswarm")` geom_beeswarm plots, and accepts arguments to customize these and rearrange the group order. As with most `Coereba` plots, we need to provide the shape and fill for our respective factors levels.

To do so for your own individual spots, you will need to specify a metadata column by which to factor by, and provide a list of shape and fill values corresponding to each factor level. 

```{r}
#| eval: FALSE
shape_ptype <- c("HU" = 22, "HEU-lo" = 21, "HEU-hi" = 21)
fill_ptype <- c("HU" = "white", "HEU-lo" = "darkgray", "HEU-hi" = "black")
```

```{r}
#| eval: FALSE
SinglePlot <- Utility_Behemoth(data=AllMarkers, var="CD62L",
  myfactor="ptype", normality="dagostino", correction="none",
  shape_palette=shape_ptype, fill_palette=fill_ptype,
  XAxisLevels = c("HU", "HEU-lo", "HEU-hi"))
```

```{r}
#| eval: FALSE
SinglePlot
```

In combination with `r CRANpkg("purrr")` we can rapidly iterate over all the markers (skipping the initial metadata colums) and generate all the plots. These can then be passed to `Luciernaga` `Utility_Patchwork()` to rearrange into patchwork objects with our desired layout, and passed to a .pdf file. 

```{r}
#| eval: FALSE
# colnames(AllMarkers)
TheLength <- length(AllMarkers)

AllPlots <- map(names(AllMarkers)[c(9:TheLength)], ~ Utility_Behemoth(data=AllMarkers, var=.x,
  myfactor="ptype", normality="dagostino", correction="none",
  shape_palette=shape_ptype, fill_palette=fill_ptype, corral.width=0.7,
  XAxisLevels = c("HU", "HEU-lo", "HEU-hi")))
```

These in turn can be passed to `Luciernaga` `Utility_Patchwork() function to arrange desired layout and output to a .pdf file for late reference. 

```{r}
#| eval: FALSE
library(Luciernaga)

StorageLocation <- file.path("C:", "Users", "JohnDoe", "Desktop")

TheAssembledPlot <- Utility_Patchwork(x=AllPlots, filename="NKT_Markers",
 outfolder=NULL, thecolumns=2, therows=3, width=7, height=9,
 returntype="patchwork")
```

```{r}
#| eval: FALSE
TheAssembledPlot[1]
```

# Utility_LongitudinalBehemoth

We can take Utility_Behemoth and cluster the x-axis on the basis of two factors. 

# Coereba_Comparison

Once we have the regular workflow, we can leverage existing Coereba metadata to determine what is different between two gated population of cells. 





# Soapbox

## Note on Cell Populations and Splitpoint

During development, we have noticed that for SFC data, the splitpoint location can vary substantially for individual cell populations (B cells, NK cells, T cells, etc), even in the abscence of biology. We believe this is due to uncertainty in the unmixing, as we have observed a correlation of negative splitpoint MFI in relation to the individual cells kappa value (matrix complexity essentially). Try your best to have the gate reflect what you are interested in, reduce the amount of error as much as you can, and in numbers veritas. Keep track of the exceptions (more later) and write up a Cyto paper. 

# Filtering Coereba Clusters 

Some things are literally poisson noise. Others are cell clusters with varying abundance across heteregenous human patients. Others are individually unique terminal nodes that can be the result of individual biology.... or unmixing errors ... or your lab tech messing up the staining panel. You can leverage the filter functions to identify all of these quickly. 

# Utility_Heatmap

The original visualization for the Coereba clusters, in a Bananaquit color-scheme. Next time someone insist there are just 5 clusters in their FlowSOM, point them here. 

```{r}
#| eval: FALSE
ThePlot <- Utility_Heatmap(binary=binaryData, panel=panelPath,
  export=FALSE, outpath=NULL, filename=NULL)
```

```{r}
#| eval: FALSE
ThePlot
```

# Background

Use of supervised (manual) analysis is widespread in flow cytometry, wherein researchers via  graphical user interface (GUI) display the acquired data for two markers, and draw gates around a cell population of potential interest. Cells within the gate are selected/filtered for, and can subsequently be gated for comparison against a different combination of markers. As additional gates are drawn, a hierarchial gating tree is assembled, allowing examination of smaller cell subsets. This approach was particularly suited to Conventional Flow Cytometry (CFC), where fast acquisition speed and relatively few markers limited presented smaller search area. In theory, if every marker was split into positive and negative gates, for a 9-color panel, 2^9 would result in 512 potential "clusters" of cells that expressed the same markers as each other, and at-least one different marker from another cluster. 

With increase in markers (both for mass cytometry (MC), and more recently by spectral flow cytometry (SFC)), the resulting combinatorial marker combinations that would need to be gated quickly exceed the capacity for supervised analysis to examine (2^39=550 billion). Consequently, unsupervised (algortihmic) methods are being employed to address this challenge. Many of these rely on clustering cells on the basis of their median fluorescent intensity (MFI) of their respective markers. One of the many unresolved questions for many of these approaches remains "How many clusters are present?" and whether the identified cell clusters are biologically meaninful. Similarly, for SFC, issues with panel unmixing can cause significant variance that in turn can contribute to batch effects. 

Additionally, for SFC datasets, the faster acquisition speed typically results in a greater number of cells being acquired compared to MC, which alongside the increased number of markers compared to CFC, requires new tools if the goal is to enable comprehensive profiling of all phenotypes present within the acquired cells. That individual cell populations may be differentially affected by improper unmixing controls presents additional challenges that may require customized gatings. 
  
Coereba is a collection of tools that attempt to implement a semi-supervised analytical approach. Using automated gating, splitpoints between positive and negative cells for every marker are estimated on an individual basis. Through extensive visualization and a ShinyApp, failures in gate setting by algorithmic gating can be adjusted by the researcher. Individual cells are then classified on the basis of these marker splitpoints, and the identity and metadata information is appended to the .fcs file. Following unsupervised analysis, this manually defined gating information can extracted and used both for analysis and verify the algorithm performed as predicted across specimens. 

The author and maintainer make no claims that Coereba is the solution to all cytometry analysis woes. It is solely a tool in the open-source toolbelt to enable you do quirky and useful things that you wouldn't be otherwise able to do with either main current approaches. Go forth, gain better understanding underlying problems our current paradigms inhabit, and may the next generation of researchers benefit from what we learn. 

Wrote the function to send the outputs to diffcyt for the edgeR/limma/GLMM modeling of the results (vs the above t-test approach). It works, but does it mean it's less p-hacky? TBD. Also, given diffcyt's current maintenance status , may not be best approach vs a new implementation. 

# How Coereba works

Having a GateCutoff.csv containing the splitpoint information for each marker validated for each individual is immensely useful, allowing you to do many things you wouldn't be capable of otherwise. Namely, we can for an individual anotate each cell within their .fcs file. 

What do I mean? Let's first think about all the cells circulating in an individuals bloostream. We don't have any prior information in this example, but we want to profile these cells into clusters of similar cells. On one end of the spectra, there is a single cluster that contains every single cell from the sample, regardless of their marker expression. At the opposite end of the spectrum, every single cell clusters in an it's own cluster with just itself. In between these two extremes, depending on our question, lies a meaningful cluster number that will match the underlying biology to reduce the amount of variance that lies in clumping/splitting populations needlessly. 

`Coereba` takes the approacch by individually annotating an individuals cells one by one, on the basis of where their MFI value lands related to the validated splitpoint. So if the splitpoint for FITC is at 50, and the individual cell MFI  for FITC is 80, it returns as FITC_pos. If the splitpoint for APC is at 70, and the individual cell MFI is 30, it returns as APC_Neg. 

When you iterate over the splitpoints for each marker, each cell derrives an identity. FITC_pos-APC_Neg-BV421_Pos.... etc. We can then group cells with matching identies and derrive information from these terminal nodes. 

Individually, this may not mean much. After all, dichotomous splitting of a 30-marker panel is around half-a billion potential terminal nodes or clusters. Similarly, cytometers have instrumental, batch, experimental noise, etc. 

But when we scale to all the events collected within a typical sample, we get far fewer terminal nodes, in the hundred to lower thousand range for a 30-color panel. The reason is cells (and the panels by which we investigate them) are not uniformely distributed by markers across high-dimensional space, cells fall within specific phenotypes (cell types) that undergo division of similar clones. 

Consequently, we can iteratively leverage the number of markers included to target questions of interest, broad or narrow scope, in context of our individual panels, and rely on methods described below to gain insight into biological systems. 

```{r sessionInfo}
#| echo: FALSE
sessionInfo()
```
