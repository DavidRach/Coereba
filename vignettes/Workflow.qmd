---
title: "Using Coereba"
package: Coereba
author:
- name: David Rach
  email: drach@som.umaryland.edu
  affiliation: University of Maryland, Baltimore
date: "`r BiocStyle::doc_date()`"
format:
  html:
    minimal: true
    theme: flatly
vignette: |
  %\VignetteIndexEntry{Workflow}
  %\VignetteKeywords{Workflow}
  %\VignettePackage{Coereba}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{quarto::html}
  %\VignetteDepends{BiocStyle}
---

```{r}
#| eval: FALSE
knitr::opts_chunk$set(
  eval = FALSE,
  collapse = TRUE,
  comment = "#>"
)
```

```{r}
#| echo: FALSE
#| warning: FALSE
#| results: "hide"

suppressPackageStartupMessages({
library(Coereba)
library(BiocStyle)
library(flowCore)
library(flowWorkspace)
library(CytoML)
library(openCyto)
library(ggcyto)  
library(data.table)
library(dplyr)
library(purrr) 
library(stringr)
library(ggplot2)
library(gt)
library(plotly)
library(htmltools)
})
```

# Setup

## Installing Coereba

We are in the process of preparing Coereba to submit to Bioconductor later this year. Until then, the developmental version can be installed via GitHub.

```{r}
#| label: "Installing Coereba"
#| eval: FALSE

if(!require("remotes")){install.packages("remotes")}
remotes::install_github("https://github.com/DavidRach/Coereba")

# install.packages("BiocManager")
# BiocManager::install("Coereba")
```

## Load Required Libraries

Coereba primarily relies on the infrastructure provided `r Biocpkg("flowWorkspace")` and other Bioconductor cytometry R packages. It additionally leverages various `r CRANpkg("tidyverse")` packages available via CRAN. Before starting, it is important to make sure all required packages are first installed, and that library is called for each to make them available. 

```{r}
#| label: "Load Libraries"

# CRAN packages: install.packages("ThePackageName")

# library(dplyr)
# library(purrr) 
# library(stringr)
# library(ggplot2)
# library(gt)
# library(plotly)
# library(htmltools)
# library(data.table)

# Bioconductor packages: BiocManager::install("ThePackageName")

library(Coereba)
#library(flowCore)
#library(flowWorkspace)
#library(openCyto)
#library(ggcyto)  

```

## Locate your files

You will next need to provide to your computer the location where your .fcs files of interest are stored. An example of how the author for various operating systems can be seen below, and should be modified to account for your own username and folder location.  

```{r}
#| label: "File Paths"
#| eval: FALSE

# For Windows Operating Systems

File_Location <- file.path("C:", "Users", "JohnDoe", "Desktop", "TodaysExperiment")
FCS_Pattern <- ".fcs$"
FCS_Files <- list.files(path = File_Location, pattern = FCS_Pattern,
                        full.names = TRUE, recursive = FALSE)

# For Mac

# For Linux
# File_Location <- file.path("/home", "JohnDoe", "Desktop", "TodaysExperiment")
```

For this vignette, we will be utilizing several downsized .fcs files that are stored within Coereba's extdata folder. 

```{r}
#| label: "Accessing Coereba's FCS files"
File_Location <- system.file("extdata", package = "Coereba")
FCS_Pattern <- ".fcs$"
FCS_Files <- list.files(path = File_Location, pattern = FCS_Pattern,
                        full.names = TRUE, recursive = FALSE)
head(FCS_Files, 3)
```

Within this folder, we have stored unmixed .fcs files from a 32 fluorophore Spectral Flow Cytometry panel. We had manually gated down to CD4-CD8- (DN) T cells, from which we downsampled up to 1000 cells to be small enough size wise for use in this documentation example.  

## Creating a GatingSet

### flowWorkspace and openCyto

Working with the unmixed .fcs files we have identified above, we will group them into a GatingSet object where we can further interact with them.

```{r}
#| label: GatingSet
UnmixedFCSFiles <- FCS_Files
UnmixedCytoSet <- load_cytoset_from_fcs(UnmixedFCSFiles, truncate_max_range = FALSE,
                                        transformation = FALSE)
UnmixedGatingSet <- GatingSet(UnmixedCytoSet)
UnmixedGatingSet
```

Now that we have created a GatingSet object, we will generate list of the fluorophores and markers present. We will then exclude from this list markers that don't require transformation (FSC, SSC, etc.) For this example, we will biexponentially transform our data using the `r Biocpkg("flowWorkspace")` `flowWorkspace::flowjo_biexp_trans()`.

```{r}
#| label: "Biexponential Transformation"
#| message: false
Markers <- colnames(UnmixedCytoSet)
KeptMarkers <- Markers[-grep("Time|FS|SC|SS|Original|-W$|-H$|AF", Markers)]

MyBiexponentialTransform <- flowjo_biexp_trans(channelRange = 256, maxValue = 1000000,
                                               pos = 4.5, neg = 0, widthBasis = -1000)
TransformList <- transformerList(KeptMarkers, MyBiexponentialTransform)
UnmixedGatingSet <- transform(UnmixedGatingSet, TransformList)
```

For this example, we will apply a `r Biocpkg("openCyto")`gating template that can be found in the extdata folder to apply a gate to distinguish Vdelta2 cells from other DN T cells. 

```{r}
#| label: "openCyto Gating"
UnmixedGates <- fread(file.path(path = File_Location, pattern = 'GatesUnmixed.csv'))
UnmixedGating <- gatingTemplate(UnmixedGates)
gt_gating(UnmixedGating, UnmixedGatingSet)
```

```{r}
plot(UnmixedGatingSet)
```

We can additionally verify that the gating of the cell populations of interest was correct, by visualizing the gates using `r Biocpkg("ggcyto")` or the Luciernaga package. 

```{r}
#| label: "Checking the openCyto gate"
library(Luciernaga)

MyPlot <- Utility_GatingPlots(x=UnmixedGatingSet[4], sample.name=c("GROUPNAME", "TUBENAME"),
                              removestrings=".fcs", subset="root", gtFile=UnmixedGates,
                              DesiredGates=NULL, returnType="plots", outpath = getwd(),
                              therows=1, thecolumns=2)

MyPlot
```

### CytoML

An alternative approach to creating a new GatingSet with `r Biocpkg("openCyto")`, would to be to import an existing FlowJo workspace using `r Biocpkg("CytoML")`. The workflow for this approach would look something as follows:

```{r}
#| label: "CytoML example"
#| eval: FALSE

# For Windows Operating Systems
folder <- file.path("C:", "Users", "JohnDoe", "Desktop", "TodaysExperiment")
wsp <- list.files(pattern=".wsp", full.names=TRUE)
```

```{r}
#| echo: FALSE
#| warning: FALSE
#| results: "hide"
folder <- system.file("extdata", package = "Coereba")
wsp <- list.files(folder, pattern=".wsp", full.names=TRUE)
```

```{r}
library(CytoML)
ws <- open_flowjo_xml(wsp[1])
CytoML_GS <- flowjo_to_gatingset(ws, name=1, path = folder, additional.keys="GROUPNAME")
CytoML_GS
```

```{r}
library(Luciernaga)

MyPlot <- Utility_GatingPlots(x=CytoML_GS[27], sample.name=c("GROUPNAME", "TUBENAME"),
                              removestrings=".fcs", subset="root", gtFile=UnmixedGates,
                              DesiredGates=NULL, returnType="plots", outpath = getwd(),
                              therows=1, thecolumns=2)

MyPlot
```

# Coereba

Having set up a GatingSet with transformations and gates applied, we can now proceed to the main `Coereba` workflow. 

For this example, we will focus on just 4 of the 32 markers, CD16 (BV570), CXCR5 (RB780), HLA-DR(PE-Vio770), and Vdelta2 (BUV661). Most cord DN T cells are negative for these markers, but 5-25% are positive, so they are good examples to showcase the gate adjustment mechanisms. The process when working with all 32-markers is similar. 

```{r}
MarkersForToday <- c("Comp-BV570-A", "Comp-RB780-A", "Comp-BUV661-A", "Comp-PE-Vio770-A")
```


## Return a Coereba Gate cutoff template

Behind the scenes, Coereba is utilizing openCyto automated gating (primarily leveraging gate_mindensity) to determine the splitpoints between the negative and positive cells. 

```{r}
# Designate a location file.path to save the calculated splitpoints .csv to. 
StorageLocationForSplitpoints <- "template"

# We will use a temp() folder for this documentation example. 
StorageLocationForSplitpoints <- tempdir()

TheGateCutoffs <- purrr::map(.x=UnmixedGatingSet, .f=Coereba_GateCutoffs,
  subset="root", sample.name=c("GROUPNAME"), desiredCols=MarkersForToday) %>% bind_rows()

TheFileName <- file.path(StorageLocationForSplitpoints, "InitialGates.csv")

write.csv(TheGateCutoffs, TheFileName, row.names=FALSE)
```

```{r}
TheGateCutoffs
```

These in turn can be visualized with the Luciernaga packages NbyN and Unity plot functions, these can be returned to R or saved as a pdf. When a marker has distinct positive or negative markers, the initial estimated location works well. 

```{r}
#| label: NbyN plot check
#| message: FALSE
#| warning: FALSE

StorageLocationForPlotPDF <- tempdir()

Plot <- Utility_NbyNPlots(x=UnmixedGatingSet[4], sample.name=c("GROUPNAME"), experiment="ABs",
condition="DNs", removestrings=".fcs", marginsubset="root", gatesubset="root", 
ycolumn="Comp-BUV661-A", bins=150, clearance=0.1, 
gatelines=TRUE, reference=TheGateCutoffs, outpath=StorageLocationForPlotPDF, returntype="patchwork")
```

```{r}
Plot
```

However, when everything is uniformly positive or negative, or more subtle, these estimated locations can be quite off. In these cases, it can be useful to provide gate_range arguments to constrain the mindensity to assign a splitpoint in a particular area. 

The simplest way to get this set up is the returnTemplate argument which will return a TemplateForGates.csv based off the openCyto template .csv.

```{r}
#| label: Return an openCyto template

# Designate a location file.path to save the template to. 
StorageLocationForTemplate <- "template"

# We will use a temp() folder for this documentation example. 
StorageLocationForTemplate <- tempdir()

ReturnATemplate <- Coereba_GateCutoffs(x=UnmixedGatingSet[1],
  subset="root", sample.name="GROUPNAME", desiredCols=MarkersForToday, 
  returnTemplate=TRUE, outpath=StorageLocationForTemplate)   
```

```{r}
TheTemplate <- list.files(StorageLocationForTemplate,
 pattern="TemplateForGates.csv", full.names=TRUE)

TheTemplateCSV <- read.csv(TheTemplate, check.names=FALSE)
```

```{r}
#| echo: FALSE
TheTemplateCSV
```

This file in turn can be updated with the gate_range arguments. 

```{r}
#On your own workstation

UpdatedTemplatePath <- file.path("C:", "Users", "JohnDoe", "Desktop",
"UpdatedTemplateForGates.csv")

# For our documentation's example

folder <- system.file("extdata", package = "Coereba")

UpdatedTemplatePath <- list.files(folder, pattern="UpdatedTemplateForGates.csv", full.names=TRUE)

UpdatedTemplate <- read.csv(UpdatedTemplatePath, check.names=FALSE)
```

```{r}
UpdatedTemplate
```

With this done, we can provide it back to Coereba_GateCutoffs with the GateOverwrite argument set to TRUE to repeat the process of calculating the splitpoints. 

```{r}
TheUpdatedGateCutoffs <- purrr::map(.x=UnmixedGatingSet, .f=Coereba_GateCutoffs,
  subset="root", sample.name="GROUPNAME", desiredCols=MarkersForToday,
  GatingTemplate=UpdatedTemplatePath, GateOverwrite=TRUE) %>% bind_rows()

# Designate a location file.path to save the template to. 
StorageLocationForUpdatedSplitpoints <- "template"

# We will use a temp() folder for this documentation example. 
StorageLocationForUpdatedSplitpoints <- tempdir()

SecondGates <- file.path(StorageLocationForUpdatedSplitpoints, "SecondGates.csv")
write.csv(TheUpdatedGateCutoffs, SecondGates, row.names=FALSE)
```

```{r}
TheUpdatedGateCutoffs
```

This ultimately allows the splitpoint gate estimates to be closer to the true positive/negative split, resulting in less total adjustments that need to be done via the Coereba Shiny app.

```{r}
#| label: NbyN plot check 2
#| message: FALSE
#| warning: FALSE

StorageLocationForPlotPDF <- tempdir()

UpdatedPlot <- Utility_NbyNPlots(x=UnmixedGatingSet[4], sample.name=c("GROUPNAME"), experiment="ABs",
condition="DNs", removestrings=".fcs", marginsubset="root", gatesubset="root", 
ycolumn="Comp-BUV661-A", bins=150, clearance=0.1, 
gatelines=TRUE, reference=TheUpdatedGateCutoffs, outpath=StorageLocationForPlotPDF, returntype="patchwork")
```

```{r}
UpdatedPlot
```

## Coereba_App

```{r}
#| eval: false

#library(DT)
#library(plotly)
#library(shiny)
#library(shinydashboard)

Coereba_App()
```

Upon launch, you are within the Upload CSV File tab on the upper left. 

![](`r system.file("extdata", "ShinyLanding.png", package = "Coereba")`){width="75%"}

Proceed to find and upload the .csv containing the updated splitpoints based on the gate_range constraints

![](`r system.file("extdata", "ShinySplitpointsLoaded.png", package = "Coereba")`){width="75%"}

Once this is done, navigate to the Upload a Gating set tab on the upper left

Proceed to fill in the details, using same name for the GatingSets and associated gates as you have currently in your environment. 

![](`r system.file("extdata", "ShinyDetailsLoaded.png", package = "Coereba")`){width="75%"}

Once this is done, click Generate Plots. If you view the console of the main R session, you will see the Utility_NbyNplot messages running as the plots are generated. 

![](`r system.file("extdata", "ShinyVisuals.png", package = "Coereba")`){width="75%"}

Scroll down to see how the splitpoints were assigned to the individual samples. When you find one that was incorrectly set, hover just above the x-axis for the correct location, and click on the spot with your mouse (see blue arrow)

![](`r system.file("extdata", "ShinyUpdating.png", package = "Coereba")`){width="75%"}

When you click just above the axis for the corrected splitpoint, you should see a click event captured message pop up in the console window of the Main R environment. 

![](`r system.file("extdata", "ConsoleClicks.png", package = "Coereba")`){width="75%"}

The process continues as you switch the x-axis marker, regenerate the plots, and then correct the splitpoints for each subsequent marker. 

![](`r system.file("extdata", "CorrectSplitpoints.png", package = "Coereba")`){width="75%"}

Once this is complete, navigate to the Click Data tab on the upper left. You will see the click events in their totality. 

![](`r system.file("extdata", "ClickDataExport.png", package = "Coereba")`){width="75%"}

Once you have entered the desired file name and the correct file path to the storage location, click Export Click Data. If this was done successfully, you should see the following notice appear. 

![](`r system.file("extdata", "CheckoutNotice.png", package = "Coereba")`){width="75%"}


The first step is to create a .csv file, containing the individual specimens, and the individual markers of interest. Each cell within the .csv file will correspond to the MFI for a given marker for a given individual where positive expression of a marker transitions to becoming a negative (referred here to as a splitpoint). 

These could be written out individually, or based on automated calculations. To simplify the process, in Coereba, we have implemented two approaches to estimating these splitpoints. One function is the in-house `Coereba_GateCutoffs()`, which does an "okay-ish but work-in progress". The flip approach is leveraging the `r Biocpkg("openCyto")` pipeline (in development) and retrieving the values. 

Both approaches can be computationally heavy, but still faster than eye-balling everything and typing in the values one-by-one. Save the eyestrain for subsequent validation steps.

```{r}
#| eval: FALSE
TheGateCutoff <- Coereba_GateCutoffs(gs=UnmixedGatingSet[1],
  subset="live", sample.name="GROUPNAME", desiredCols =c("BUV805-A"))

TheGateCutoffs <- map(.x=UnmixedGatingSet[1:3], .f=Coereba_GateCutoffs,
  subset="live", sample.name="GROUPNAME", desiredCols =c("BUV805-A")) %>% bind_rows()
```

```{r}
#| eval: FALSE
TheGateCutoffs
```

# Visualizing Gate Cutoffs

Once we have generated a GateCutoffs.csv file, we can visualize how well the splitpoints were by plotting them as red-lines using the `Luciernaga` packages `Utility_NbyNPlots()` to visualize the markers for a given individual and `Utility_UnityPlots()` to visualize the markers across individuals. This a good way of understanding how well the competing gating-algorithms did in the context of your individual panel, and how much effort will be required for the next step in correcting the gates individually. 

```{r}
#| eval: FALSE
print("Hello")
```

# Coereba_App

Previously, all adjustments to the above splitpoints had to eye-balled in the pdf, and then adjusted in the .csv file, and repeated ad nauseum. This obviously did not scale well. We have subsequently created a ShinyApp that will bring in the GatingSet object, and plot an interactive version of `Utility_UnityPlot()` from the `Luciernaga` package, visualizing the splitpoint for a given marker across all individuals as red vertical lines. 

To get started, first make sure you know where the `Coereba_GateCutoffs()` .csv output is saved at, as you will need to select the file within the App. 

```{r}
#| eval: FALSE
File_Location <- system.file("extdata", package = "Coereba")
TheCSV <- file.path(File_Location, "GateCutoffsForNKs.csv")
TheCSVData <- read.csv(TheCSV, check.names=FALSE)
head(TheCSVData)
```

Next, make sure to remember the name of your GatingSet ("UnmixedGatingSet" for this case), and the sample.name keyword to identify individual specimens, as you will need to input these values within the app. 

Then, run the following command in your console:

```{r}
#| eval: FALSE
Coereba_App()
```

The first tab view will let you upload the GateCutoff.csv file generated by the previous function, by letting you navigate to the storage folder and clicking on it. 

Once this is done, navigate to the Upload a GatingSet tab. Enter the information about your GatingSet ("UnmixedGatingSet" for this example), select your x and y parameters, enter the SampleName keyword. Desired bins allows adjustments to the visualization given the number of cells present, clearance multiplier adjust the margins wiggle-room, removestrings arguments. You specify margin and gate subsets like you would for `Utility_UnityPlots()` and click Display Estimated Gate Cutoffs. Finally, you click on Generate Plots and go retrieve your coffee/tea/beverage-of-choice.  

Upon loading of the plots, scroll until you encounter a splitpoint line that was placed incorrectly, you can simply click on the correct location of the axis, which will save the coordinate as a splitpoint for that given marker and individual to a data.frame. This will later be ported to update the corresponding splitpoint value for a given marker and individual in the exisiting GateCutoff .csv. By just clicking, you can therefore quickly correct cases where the algorithm failed to gate properly due to batch effects, bad staining, or algorithmic incompetence (sorry, the coders are still learning as well).

Once you have corrected some/all the markers, navigate to the Click Data tab. You can then export the click-data information by specifying a filename and providing an outpath to the folder you want to save at. Unfortunately, due to security issues in ShinyApps, you will need to type out the designated outpath manually.

And repeat until the markers you are interested have been validated and you have a folder of clickpoint .csvs awaiting conversion into the existing GateCutoff folder. 

Since the code is within a ShinyApp running in R, it has both the advantages and disadvantages of a R Shiny App. It scales reasonably well, but can take a while to load the next iterated marker. During testing, loading a new marker to inspect took anywhere from 3-10 additional minutes. This area is a active work in progress to speed up, but the author/maintainer hasn't had the time to finish reading Mastering Shiny by Hadley Wickham yet or implement it in Rust, if you have, feel free to assist!

# Coereba_UpdateGates

Once you have completed validating the GateCutoffs with `Coereba_App()`, it is time to convert your validated click-data and update the GateCutoff.csv. To fascilitate this, provide the location of the folder containing just the clickpoint .csv's to  `Coereba_UpdateGates()` and fill out the required arguments. It will proceed to update the GateCutoffs. 

For this example, we will use ClickDataExamples.csv stored within `Coereba`'s extdata folder:

```{r}
#| eval: FALSE
File_Location <- system.file("extdata", package = "Coereba")
TheOldCSV <- file.path(File_Location, "GateCutoffsForNKs.csv")
TheClickInfo <- file.path(File_Location, "ClickDataExample.csv")
TheClickData <- read.csv(TheClickInfo, check.names=FALSE)
TheClickData
```

The old data:
```{r}
#| eval: FALSE
TheOldData <- read.csv(TheOldCSV, check.names=FALSE)
TheOldData
```

We can then run `Coereba_UpdateGates()` and watch the values for BUV469-A are updated.
```{r}
#| eval: FALSE
UpdatedCSV <- Coereba_UpdateGates(Clicks=TheClickInfo, Old=TheOldCSV,
  export=FALSE, outpath=NULL, fileName="UpdatedCSV")

UpdatedCSV
```

We can further validate this by re-running `Luciernaga` `Utility_UnityPlots()` using the updated GateCutoff.csv and seeing if the previous issues have been corrected. 

# Note on Cell Populations and Splitpoint

During development, we have noticed that for SFC data, the splitpoint location can vary substantially for individual cell populations (B cells, NK cells, T cells, etc), even in the abscence of biology. We believe this is due to uncertainty in the unmixing, as we have observed a correlation of negative splitpoint MFI in relation to the individual cells kappa value (matrix complexity essentially). Try your best to have the gate reflect what you are interested in, reduce the amount of error as much as you can, and in numbers veritas. Keep track of the exceptions (more later) and write up a Cyto paper. 

# Utility_Coereba

`Utility_Coereba()` is the function that implements the above approach, labelling for each individual specimen the individual cells on the basis of their splitpoint identity, and then returning the enumeration of the resulting clusters. It iterates over the different specimens in the GatingSet, returning information for every individual that can be used in subsequent steps. `MultiReach()` is the older version of the proccess.

Both functions are currently waiting on the ILT paper to be sent to collaborators so that David can implement his 5-subject binder worth of notes to implement a S4 OOP class to make manipulating the final outputs easier than the current .qmd files full of tidyverse data tidying. 

```{r}
#| eval: FALSE
#| warning: false

CoerebaIDs <- Utility_Coereba(x=UnmixedGatingSet[1], subsets="live",
  sample.name="GROUPNAME", reference=TheCSV, starter="Spark Blue 550-A")
```

```{r}
#| eval: FALSE
head(CoerebaIDs, 5)
```


# Filtering Coereba Clusters 

Some things are literally poisson noise. Others are cell clusters with varying abundance across heteregenous human patients. Others are individually unique terminal nodes that can be the result of individual biology.... or unmixing errors ... or your lab tech messing up the staining panel. You can leverage the filter functions to identify all of these quickly. 

```{r}
#| eval: FALSE
print("Hello")
```

# Coereba_MarkerExpressions

Having generated a Marker by Cluster data.frame (binaryData) and a Cluster by Specimen data.frame (dataData), we can leverage the combination of the two data.frames to aggregate the clusters on the basis of marker presence, returning the proportion of of cells that are positive for a given marker. 

For this demonstration, we will focus on NKTs, using stored .csv files for their binary and data outputs stored within the Coereba extdata folder.

```{r}
#| eval: FALSE
File_Location <- system.file("extdata", package = "Coereba")

panelPath <- file.path(File_Location, "ILTPanelTetramer.csv")
panelData <- read.csv(panelPath, check.names=FALSE)

binaryPath <- file.path(File_Location, "HeatmapExample.csv")
binaryData <- read.csv(binaryPath, check.names=FALSE)

dataPath <- file.path(File_Location, "ReadyFileExample.csv")
dataData <- read.csv(dataPath, check.names=FALSE)
```

We will first just return the marker expressions for all markers: 
```{r}
#| eval: FALSE
library(Coereba)

AllMarkers <- Coereba_MarkerExpressions(data=dataData, binary=binaryData,
  panel=panelData, starter="SparkBlue550")
  
head(AllMarkers, 5)
```

We can additionally by specifying returnType = "Combinatorial" derrive proportions within quadrant gates for
two markers of interest. To do so, we specify the fluorophores corresponding to the markers as a list in the CombinatorialArgs.

```{r}
#| eval: FALSE
MemoryQuadrants <- Coereba_MarkerExpressions(data=dataData, binary=binaryData,
  panel=panelData, starter="SparkBlue550", returnType = "Combinatorial", 
  CombinatorialArgs = c("BV510", "BUV395"))

head(MemoryQuadrants, 5)
```

# Utility_MarkerPlots

Having returned aggregated data above with `Coereba_MarkerExpressions`, we can plot this data using `Utility_MarkerPlots()`. These are combination of `r CRANpkg("ggplot2")` geom_boxplot() and `r CRANpkg("ggbeeswarm")` geom_beeswarm plots. We provide some arguments that allow for filtering and reordering the markers shown in these plots, some basic customizations to the plots, and the ability to save as a .png file to a designated folder. 

To do so for your own individual spots, you will need to specify a metadata column by which to factor by, and provide a list of shape and fill values corresponding to each factor level. 

```{r}
#| eval: FALSE
shape_ptype <- c("HU" = 22, "HEU-lo" = 21, "HEU-hi" = 21)
fill_ptype <- c("HU" = "white", "HEU-lo" = "darkgray", "HEU-hi" = "black")
```

We can start by viewing all markers:

```{r}
#| eval: FALSE
#| warning: FALSE

ThePlot <- Utility_MarkerPlots(data=AllMarkers, panel=panelData,
  myfactor="ptype", shape_palette = shape_ptype, fill_palette = fill_ptype)

ThePlot
```

Let's abbreviate the number of columns by specifying the marker names to include (filterForThese), and rearrange them in desired X-axis order

```{r}
#| eval: FALSE
ThePlot <- Utility_MarkerPlots(data=AllMarkers, panel=panelData,
  myfactor="ptype", shape_palette = shape_ptype, fill_palette = fill_ptype,
  filterForThese=c("CD7", "CD4", "CD8"), XAxisLevels = c("CD7", "CD4", "CD8"))

ThePlot
```

And to ggsave directly to a desired folder:

```{r}
#| eval: FALSE
print("Hello")
```

# Utility_Stats

The `Utility_Stats()` and the `Utility_Behemoth()` functions are either: "Great!!!", or guaranteed to make your friendly-local statistician cry (Opinions vary). 

Basically, `Utility_Stats()` is a coding-attempt to replicate the typical immunologist workflow, cutting out the need to copy-paste data from a .csv file into GraphPad Prism (trademark), run a normality test, determine number of groups, and follow up with the corresponding t-test/anova/non-parametric equivalents. `Utility_Behemoth()` then takes these outputs, and adds the p-value results to a ggbeeswarm/ggplot2 boxplot of the underlying data. In combination with `r CRANpkg("purrr")` and `Luciernaga` `Utility_Patchwork()`, these can be quickly formatted into a .pdf. 

Does this workflow rapidly profile all the columns in your data.frame. Yes it does. Is it emblematic of potential issues arising from basing science entirely on null-hypothesis statistical testing? Also yes, seeing how many plots return "significant" due to a couple outliers. In the end, it mimics the current workflow of many researchers, just speeding it up. Google Statistical Rethinking on YouTube for food-for-thought.

To begin, we will use the `Coereba_MarkerExpressions` data we generated above to test out `Utility_Stats()`. 

```{r}
#| eval: FALSE
Result <- Utility_Stats(data=AllMarkers, var="CD62L",
  myfactor="ptype", normality="dagostino", correction="none")

Result
```

In combination with `r CRANpkg("purrr")` we can rapidly iterate over all the markers, but will need to skip over the metadata columns that are present at the begining of the dataframe. 

```{r}
#| eval: FALSE
library(purrr)
library(dplyr)
# colnames(AllMarkers)
TheLength <- ncol(AllMarkers)

TheData <- map(names(AllMarkers)[c(9:TheLength)], ~ Utility_Stats(
  data = AllMarkers, var = .x, myfactor = "ptype", 
  normality = "dagostino")) %>% bind_rows()
```

The results can be filtered using regular `r CRANpkg("dplyr")` functions.

```{r}
#| eval: FALSE
MaybeSignificant <- TheData %>% dplyr::filter(pvalue < 0.05)

MaybeSignificant
```

# Utility_Behemoth

`Utility_Behemoth()` continues from where `Utility_Stats()` left-off, appending the resulting p-value information onto a ggplot2 plot. The plot is a combination of `r CRANpkg("ggplot2")` geom_boxplot() and `r CRANpkg("ggbeeswarm")` geom_beeswarm plots, and accepts arguments to customize these and rearrange the group order. As with most `Coereba` plots, we need to provide the shape and fill for our respective factors levels.

To do so for your own individual spots, you will need to specify a metadata column by which to factor by, and provide a list of shape and fill values corresponding to each factor level. 

```{r}
#| eval: FALSE
shape_ptype <- c("HU" = 22, "HEU-lo" = 21, "HEU-hi" = 21)
fill_ptype <- c("HU" = "white", "HEU-lo" = "darkgray", "HEU-hi" = "black")
```

```{r}
#| eval: FALSE
SinglePlot <- Utility_Behemoth(data=AllMarkers, var="CD62L",
  myfactor="ptype", normality="dagostino", correction="none",
  shape_palette=shape_ptype, fill_palette=fill_ptype,
  XAxisLevels = c("HU", "HEU-lo", "HEU-hi"))
```

```{r}
#| eval: FALSE
SinglePlot
```

In combination with `r CRANpkg("purrr")` we can rapidly iterate over all the markers (skipping the initial metadata colums) and generate all the plots. These can then be passed to `Luciernaga` `Utility_Patchwork()` to rearrange into patchwork objects with our desired layout, and passed to a .pdf file. 

```{r}
#| eval: FALSE
# colnames(AllMarkers)
TheLength <- length(AllMarkers)

AllPlots <- map(names(AllMarkers)[c(9:TheLength)], ~ Utility_Behemoth(data=AllMarkers, var=.x,
  myfactor="ptype", normality="dagostino", correction="none",
  shape_palette=shape_ptype, fill_palette=fill_ptype, corral.width=0.7,
  XAxisLevels = c("HU", "HEU-lo", "HEU-hi")))
```

These in turn can be passed to `Luciernaga` `Utility_Patchwork() function to arrange desired layout and output to a .pdf file for late reference. 

```{r}
#| eval: FALSE
library(Luciernaga)

StorageLocation <- file.path("C:", "Users", "JohnDoe", "Desktop")

TheAssembledPlot <- Utility_Patchwork(x=AllPlots, filename="NKT_Markers",
 outfolder=NULL, thecolumns=2, therows=3, width=7, height=9,
 returntype="patchwork")
```

```{r}
#| eval: FALSE
TheAssembledPlot[1]
```


# Utility_Heatmap

The original visualization for the Coereba clusters, in a Bananaquit color-scheme. Next time someone insist there are just 5 clusters in their FlowSOM, point them here. 

```{r}
#| eval: FALSE
ThePlot <- Utility_Heatmap(binary=binaryData, panel=panelPath,
  export=FALSE, outpath=NULL, filename=NULL)
```

```{r}
#| eval: FALSE
ThePlot
```

# Background

Use of supervised (manual) analysis is widespread in flow cytometry, wherein researchers via  graphical user interface (GUI) display the acquired data for two markers, and draw gates around a cell population of potential interest. Cells within the gate are selected/filtered for, and can subsequently be gated for comparison against a different combination of markers. As additional gates are drawn, a hierarchial gating tree is assembled, allowing examination of smaller cell subsets. This approach was particularly suited to Conventional Flow Cytometry (CFC), where fast acquisition speed and relatively few markers limited presented smaller search area. In theory, if every marker was split into positive and negative gates, for a 9-color panel, 2^9 would result in 512 potential "clusters" of cells that expressed the same markers as each other, and at-least one different marker from another cluster. 

With increase in markers (both for mass cytometry (MC), and more recently by spectral flow cytometry (SFC)), the resulting combinatorial marker combinations that would need to be gated quickly exceed the capacity for supervised analysis to examine (2^39=550 billion). Consequently, unsupervised (algortihmic) methods are being employed to address this challenge. Many of these rely on clustering cells on the basis of their median fluorescent intensity (MFI) of their respective markers. One of the many unresolved questions for many of these approaches remains "How many clusters are present?" and whether the identified cell clusters are biologically meaninful. Similarly, for SFC, issues with panel unmixing can cause significant variance that in turn can contribute to batch effects. 

Additionally, for SFC datasets, the faster acquisition speed typically results in a greater number of cells being acquired compared to MC, which alongside the increased number of markers compared to CFC, requires new tools if the goal is to enable comprehensive profiling of all phenotypes present within the acquired cells. That individual cell populations may be differentially affected by improper unmixing controls presents additional challenges that may require customized gatings. 
  
Coereba is a collection of tools that attempt to implement a semi-supervised analytical approach. Using automated gating, splitpoints between positive and negative cells for every marker are estimated on an individual basis. Through extensive visualization and a ShinyApp, failures in gate setting by algorithmic gating can be adjusted by the researcher. Individual cells are then classified on the basis of these marker splitpoints, and the identity and metadata information is appended to the .fcs file. Following unsupervised analysis, this manually defined gating information can extracted and used both for analysis and verify the algorithm performed as predicted across specimens. 

The author and maintainer make no claims that Coereba is the solution to all cytometry analysis woes. It is solely a tool in the open-source toolbelt to enable you do quirky and useful things that you wouldn't be otherwise able to do with either main current approaches. Go forth, gain better understanding underlying problems our current paradigms inhabit, and may the next generation of researchers benefit from what we learn. 

Wrote the function to send the outputs to diffcyt for the edgeR/limma/GLMM modeling of the results (vs the above t-test approach). It works, but does it mean it's less p-hacky? TBD. Also, given diffcyt's current maintenance status , may not be best approach vs a new implementation. 

# How Coereba works

Having a GateCutoff.csv containing the splitpoint information for each marker validated for each individual is immensely useful, allowing you to do many things you wouldn't be capable of otherwise. Namely, we can for an individual anotate each cell within their .fcs file. 

What do I mean? Let's first think about all the cells circulating in an individuals bloostream. We don't have any prior information in this example, but we want to profile these cells into clusters of similar cells. On one end of the spectra, there is a single cluster that contains every single cell from the sample, regardless of their marker expression. At the opposite end of the spectrum, every single cell clusters in an it's own cluster with just itself. In between these two extremes, depending on our question, lies a meaningful cluster number that will match the underlying biology to reduce the amount of variance that lies in clumping/splitting populations needlessly. 

`Coereba` takes the approacch by individually annotating an individuals cells one by one, on the basis of where their MFI value lands related to the validated splitpoint. So if the splitpoint for FITC is at 50, and the individual cell MFI  for FITC is 80, it returns as FITC_pos. If the splitpoint for APC is at 70, and the individual cell MFI is 30, it returns as APC_Neg. 

When you iterate over the splitpoints for each marker, each cell derrives an identity. FITC_pos-APC_Neg-BV421_Pos.... etc. We can then group cells with matching identies and derrive information from these terminal nodes. 

Individually, this may not mean much. After all, dichotomous splitting of a 30-marker panel is around half-a billion potential terminal nodes or clusters. Similarly, cytometers have instrumental, batch, experimental noise, etc. 

But when we scale to all the events collected within a typical sample, we get far fewer terminal nodes, in the hundred to lower thousand range for a 30-color panel. The reason is cells (and the panels by which we investigate them) are not uniformely distributed by markers across high-dimensional space, cells fall within specific phenotypes (cell types) that undergo division of similar clones. 

Consequently, we can iteratively leverage the number of markers included to target questions of interest, broad or narrow scope, in context of our individual panels, and rely on methods described below to gain insight into biological systems. 

```{r sessionInfo}
#| echo: FALSE
sessionInfo()
```
